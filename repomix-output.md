This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-08-31 11:31:24

# File Summary

## Purpose:

This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format:

The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
   a. A header with the file path (## File: path/to/file)
   b. The full contents of the file in a code block

## Usage Guidelines:

- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes:

- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Information:

For more information about Repomix, visit: https://github.com/andersonby/python-repomix


# Repository Structure

```
.gitignore
frontend
  index.html
  script.js
README.md
repomix-output.md
reqs.txt
server
  app
    main.py
    __init__.py
  pytest.ini
  README.md
  requirements.txt
  tests
    conftest.py
    test_compare_endpoint.py
    test_e2e_uvicorn_debug.py
    test_e2e_uvicorn_live_llm.py
    test_extract_crawl.py
    test_filters.py
    test_groq_env.py
    test_paths_exts.py
    test_repo_ref_fallback.py
    test_safe_json.py
    _e2e_utils.py
    __init__.py
styles.css
```

# Repository Files


## .gitignore

```text
# === OS / Editors ===
.DS_Store
Thumbs.db
Icon?
*~
*.swp
*.swo
.vscode/
.idea/

# === Node / Frontend (future-proof) ===
node_modules/
.next/
dist/
build/
.cache/
.parcel-cache/
*.map
# keep lockfiles if you add them later
# !package-lock.json
# !yarn.lock
# !pnpm-lock.yaml

# === Python / FastAPI ===
__pycache__/
*.py[cod]
*.pyd
*.pyo
*.so
*.egg
*.egg-info/
.eggs/
.build/
develop-eggs/
dist/
sdist/
wheels/
share/python-wheels/
.manifest
.installed.cfg

# Virtual envs (root or server/)
.venv/
server/.venv/
.env
.env.*
!.env.example

# Type check / linters / tooling caches
.mypy_cache/
.pytest_cache/
.ruff_cache/
.pytype/
.pyright/
.pyre/

# Coverage / test outputs
.coverage
.coverage.*
htmlcov/
coverage.xml
junit*.xml

# Logs
logs/
*.log
uvicorn*.log

# === Project-specific ===
# GitHub App keys / secrets
*.pem
*.key

# Repomix / bundles / dumps
repomix*.txt
*repomix*.txt
*.bundle.txt

# Frontend artifacts (old/ or frontend/ if you later add tooling)
frontend/.cache/
frontend/dist/
old/.cache/
old/dist/

# Misc caches
*.tmp
*.temp
.tmp/
.cache/

# OS metadata in subdirs
frontend/.DS_Store
old/.DS_Store
server/.DS_Store
```

## frontend/index.html

```html
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>legacy.exe – compare</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 64 64'%3E%3Ctext y='50' x='8' font-size='48'%3E⚙%3C/text%3E%3C/svg%3E">
  <style>
    :root{--bg:#0d0d0f;--fg:#e6e6eb;--muted:#8a8a93;--accent:#ff2a6d;--ok:#24d18a;--card:#141418;--border:#1f1f25}
    *{box-sizing:border-box} html,body{height:100%}
    body{margin:0;background:linear-gradient(180deg,#0b0b0d,#0e0e12);color:var(--fg);font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif}
    header{padding:20px;display:flex;align-items:flex-end;gap:10px}
    h1{margin:0;font-size:22px;letter-spacing:.5px}
    .sub{color:var(--muted);font-size:13px}
    main{padding:12px 20px 40px;max-width:1100px;margin:0 auto}
    .panel{background:var(--card);border:1px solid var(--border);border-radius:14px;padding:16px;margin-bottom:16px}
    .grid{display:grid;grid-template-columns:repeat(4,1fr);gap:10px}
    @media (max-width:1000px){.grid{grid-template-columns:repeat(2,1fr)}}
    @media (max-width:640px){.grid{grid-template-columns:1fr}}
    .row{display:flex;flex-direction:column;gap:6px}
    label{font-size:12px;color:var(--muted)}
    input,textarea{width:100%;background:#0f0f13;color:var(--fg);border:1px solid var(--border);border-radius:10px;padding:10px;font-size:14px;outline:none}
    textarea{min-height:140px;font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;line-height:1.35}
    button{background:var(--accent);color:#fff;border:none;border-radius:10px;padding:10px 14px;font-weight:700;cursor:pointer}
    .muted{color:var(--muted);font-size:12px}
    .banner{padding:10px 12px;border-radius:10px;margin-bottom:10px}
    .banner.error{background:#3a0c12;border:1px solid #6b0f1a;color:#ffd3da}
    pre{background:#0f0f13;border:1px solid var(--border);padding:12px;border-radius:10px;overflow:auto;max-height:360px;white-space:pre-wrap}
    details{border:1px solid var(--border);border-radius:10px;margin-bottom:8px;background:#0f0f13}
    details>summary{cursor:pointer;padding:10px 12px;color:var(--fg)}
    details pre{margin:0;border:none;border-top:1px solid var(--border);border-radius:0 0 10px 10px}
    .cols{display:grid;grid-template-columns:2fr 1fr;gap:16px}
    @media (max-width:900px){.cols{grid-template-columns:1fr}}
    ul{margin:6px 0;padding-left:18px}
    .row-inline{display:flex;align-items:center;gap:8px}
    .file-actions{display:flex;gap:8px;padding:8px 12px}
    .ghost{background:transparent;border:1px solid var(--border);color:var(--fg)}
    .checks{display:flex;gap:12px;align-items:center;flex-wrap:wrap;font-size:13px;color:var(--muted)}
    .checks label{display:flex;gap:6px;align-items:center}
  </style>
</head>
<body>
  <header>
    <h1>legacy.exe</h1>
    <div class="sub">compare</div>
  </header>

  <main>
    <section class="panel">
      <div id="api-offline" class="banner error" style="display:none">API offline (http://127.0.0.1:8000)</div>
      <div class="grid">
        <div class="row">
          <label>API base (backend)</label>
          <input id="api-base" placeholder="http://127.0.0.1:8000" value="http://127.0.0.1:8000" />
        </div>

        <div class="row">
          <label>LLM API URL</label>
          <input id="llm-url" placeholder="https://api.groq.com/openai/v1/chat/completions  •  https://generativelanguage.googleapis.com/v1beta" />
        </div>
        <div class="row">
          <label>LLM API Key</label>
          <input id="llm-key" type="password" placeholder="chave do provedor (Groq ou Gemini)" />
        </div>
        <div class="row">
          <label>LLM Model</label>
          <input id="model" placeholder="llama-3.1-8b-instant  •  gemma-3-27b-it" />
        </div>

        <div class="row">
          <label>repo</label>
          <input id="repo" placeholder="org/repo" />
        </div>
        <div class="row">
          <label>branch</label>
          <input id="branch" placeholder="main" value="main" />
        </div>
        <div class="row">
          <label>extensões</label>
          <input id="exts" placeholder=".py,.js,.java" value=".py,.js,.java" />
        </div>
        <div class="row">
          <label>paths</label>
          <input id="paths" placeholder="/ (tudo) • ou src/,app/" />
        </div>

        <div class="row">
          <label>GitHub PAT (opcional)</label>
          <input id="pat" type="password" placeholder="token para repos privados" />
        </div>
      </div>

      <div class="checks" style="margin-top:8px">
        <label><input type="checkbox" id="allow-placeholders"> allow placeholders</label>
        <label><input type="checkbox" id="debug-echo-raw"> debug echo raw</label>
      </div>

      <div class="row" style="margin-top:8px">
        <label>requisitos</label>
        <textarea id="reqs" placeholder="Sem codigo duplicado!"></textarea>
      </div>

      <div class="row-inline" style="margin-top:10px">
        <button id="run">comparar</button>
        <button id="download-all" class="ghost">baixar todos</button>
        <span class="muted" id="status"></span>
      </div>
    </section>

    <section class="panel">
      <div class="cols">
        <div>
          <h3 style="margin:8px 0;color:var(--muted)">Relatório</h3>
          <pre id="report"><code></code></pre>
        </div>
        <div>
          <h3 style="margin:8px 0;color:var(--muted)">Resumo</h3>
          <ul id="summary"></ul>
        </div>
      </div>

      <h3 style="margin:12px 0;color:var(--muted)">Arquivos Atualizados</h3>
      <div id="files"></div>

      <h3 style="margin:12px 0;color:var(--muted)">Raw (debug)</h3>
      <pre id="raw"><code></code></pre>
    </section>
  </main>

  <script src="./script.js" type="module"></script>
</body>
</html>
```

## frontend/script.js

```javascript
// minimal compare-only client

const $ = (q) => document.querySelector(q);
const setText = (node, text) => (node.textContent = text ?? "");
const bullets = (node, items) => {
  node.innerHTML = "";
  (items || []).slice(0, 64).forEach((x) => {
    const li = document.createElement("li");
    li.textContent = String(x);
    node.appendChild(li);
  });
};
const copyText = (t) => navigator.clipboard?.writeText(t).catch(()=>{});
function download(name, text){
  const a=document.createElement("a");
  a.href=URL.createObjectURL(new Blob([text],{type:"text/plain"}));
  a.download=name||"arquivo.txt"; a.click(); URL.revokeObjectURL(a.href);
}
function parseCSV(str) {
  return String(str || "")
    .split(",")
    .map((s) => s.trim())
    .filter(Boolean);
}

// Strong steering so the model avoids placeholders:
const PROMPT_BASE = `
- Responda SOMENTE JSON válido UTF-8, sem markdown.
- Não use placeholders como "conteúdo do ..." ou "resultado disponível em".
- Preencha "report" com 3–10 bullets técnicos e acionáveis (português).
- "summary": lista de 3–8 decisões, riscos ou próximos passos.
- "updated_files": crie apenas arquivos REAIS do projeto; evite duplicar arquivos existentes sem necessidade.
- Se for Python, os arquivos devem terminar com .py e conter código válido (ex.: imports, def, if __name__).
- Evite criar pastas artificiais (ex.: "resultados/v1/").
- Se não houver nada para mudar, mantenha "updated_files": [] e explique o porquê no "report".
`.trim();

let lastFiles = [];

function renderFiles(files) {
  lastFiles = files || [];
  const root = $("#files");
  root.innerHTML = "";
  (lastFiles).forEach((f) => {
    const details = document.createElement("details");
    const sum = document.createElement("summary");
    sum.textContent = f.path || "(sem nome)";

    const actions = document.createElement("div");
    actions.className = "file-actions";
    const bCopy = document.createElement("button");
    bCopy.className = "ghost";
    bCopy.textContent = "copiar";
    bCopy.addEventListener("click", (e)=>{ e.preventDefault(); copyText(f.content||""); });

    const bDl = document.createElement("button");
    bDl.className = "ghost";
    bDl.textContent = "baixar";
    bDl.addEventListener("click", (e)=>{ e.preventDefault(); download(f.path||"arquivo.txt", f.content||""); });

    actions.appendChild(bCopy);
    actions.appendChild(bDl);

    const pre = document.createElement("pre");
    const code = document.createElement("code");
    code.textContent = f.content || "";
    pre.appendChild(code);

    details.appendChild(sum);
    details.appendChild(actions);
    details.appendChild(pre);
    root.appendChild(details);
  });
}

function offlineBanner(show) {
  $("#api-offline").style.display = show ? "block" : "none";
}

async function runCompare() {
  const API_BASE = $("#api-base").value.trim() || "http://127.0.0.1:8000";

  // LLM (provider-agnostic)
  const llm_api_url = $("#llm-url").value.trim();       // Groq OpenAI endpoint OR Gemini v1beta base
  const llm_api_key = $("#llm-key").value.trim();
  const model       = $("#model").value.trim();

  const repo = $("#repo").value.trim();
  const branch = $("#branch").value.trim() || "main";
  const include_ext = parseCSV($("#exts").value);
  const raw_paths = parseCSV($("#paths").value);
  const include_paths = raw_paths.length ? raw_paths : ["/"]; // default: whole repo
  const requisitos = $("#reqs").value;
  const github_pat = $("#pat").value.trim() || null;

  const allow_placeholders = $("#allow-placeholders").checked;
  const debug_echo_raw = $("#debug-echo-raw").checked;

  const debug_no_llm = !(llm_api_key && model && llm_api_url);

  $("#status").textContent = "enviando...";
  offlineBanner(false);
  setText($("#report code"), "");
  $("#summary").innerHTML = "";
  $("#files").innerHTML = "";
  setText($("#raw code"), "");

  try {
    const r = await fetch(`${API_BASE}/compare`, {
      method: "POST",
      headers: { "content-type": "application/json" },
      body: JSON.stringify({
        repo,
        branch,
        include_ext,
        include_paths,
        requisitos,
        github_pat,
        debug_no_llm,
        // generic LLM config
        llm_api_url,
        llm_api_key,
        model,
        // steering + toggles
        prompt_base: PROMPT_BASE,
        allow_placeholders,
        debug_echo_raw,
      }),
    });

    const text = await r.text();
    if (!r.ok) {
      let msg = text;
      try {
        const j = JSON.parse(text);
        msg = j.detail || text;
      } catch {}
      throw new Error(msg);
    }

    const j = JSON.parse(text);
    setText($("#report code"), j.report || "");
    bullets($("#summary"), j.summary || []);
    renderFiles(j.updated_files || []);
    if (j.raw) setText($("#raw code"), j.raw);
    $("#status").textContent = "ok";
  } catch (e) {
    $("#status").textContent = "erro";
    offlineBanner(true);
    setText($("#report code"), "");
    bullets($("#summary"), [`falha: ${String(e).slice(0, 400)}`]);
    $("#files").innerHTML = "";
    setText($("#raw code"), "");
    lastFiles = [];
  }
}

document.addEventListener("DOMContentLoaded", () => {
  $("#run").addEventListener("click", runCompare);
  $("#download-all").addEventListener("click", ()=>{
    for (const f of lastFiles) download(f.path||"arquivo.txt", f.content||"");
  });

  // quick deep-linking
  const q = new URLSearchParams(location.search);
  if (q.get("api")) $("#api-base").value = q.get("api");
  if (q.get("llm")) $("#llm-url").value = q.get("llm");
  if (q.get("llm_key")) $("#llm-key").value = q.get("llm_key");
  if (q.get("model")) $("#model").value = q.get("model");
  if (q.get("repo")) $("#repo").value = q.get("repo");
  if (q.get("branch")) $("#branch").value = q.get("branch");
  if (q.get("exts")) $("#exts").value = q.get("exts");
  if (q.get("paths")) $("#paths").value = q.get("paths");
  if (q.get("allow")) $("#allow-placeholders").checked = q.get("allow") === "1";
  if (q.get("raw")) $("#debug-echo-raw").checked = q.get("raw") === "1";
  if (q.get("autorun") === "1") runCompare();
});
```

## README.md

```markdown

```

## repomix-output.md

`````markdown
This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-08-31 11:22:17

# File Summary

## Purpose:

This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format:

The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
   a. A header with the file path (## File: path/to/file)
   b. The full contents of the file in a code block

## Usage Guidelines:

- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes:

- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Information:

For more information about Repomix, visit: https://github.com/andersonby/python-repomix


# Repository Structure

```
frontend
  index.html
  script.js
old
  index.html
  js
    api_byo.js
    app.js
    config.js
    diff.js
    ui.js
    util.js
README.md
reqs.txt
server
  .env.example
  app
    main.py
    __init__.py
  pytest.ini
  README.md
  requirements.txt
  tests
    conftest.py
    test_compare_endpoint.py
    test_e2e_uvicorn_debug.py
    test_e2e_uvicorn_live_llm.py
    test_extract_crawl.py
    test_filters.py
    test_groq_env.py
    test_paths_exts.py
    test_repo_ref_fallback.py
    test_safe_json.py
    _e2e_utils.py
    __init__.py
styles.css
```

# Repository Files


## frontend/index.html

```html
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>legacy.exe – compare</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 64 64'%3E%3Ctext y='50' x='8' font-size='48'%3E⚙%3C/text%3E%3C/svg%3E">
  <style>
    :root{--bg:#0d0d0f;--fg:#e6e6eb;--muted:#8a8a93;--accent:#ff2a6d;--ok:#24d18a;--card:#141418;--border:#1f1f25}
    *{box-sizing:border-box} html,body{height:100%}
    body{margin:0;background:linear-gradient(180deg,#0b0b0d,#0e0e12);color:var(--fg);font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif}
    header{padding:20px;display:flex;align-items:flex-end;gap:10px}
    h1{margin:0;font-size:22px;letter-spacing:.5px}
    .sub{color:var(--muted);font-size:13px}
    main{padding:12px 20px 40px;max-width:1100px;margin:0 auto}
    .panel{background:var(--card);border:1px solid var(--border);border-radius:14px;padding:16px;margin-bottom:16px}
    .grid{display:grid;grid-template-columns:repeat(4,1fr);gap:10px}
    @media (max-width:1000px){.grid{grid-template-columns:repeat(2,1fr)}}
    @media (max-width:640px){.grid{grid-template-columns:1fr}}
    .row{display:flex;flex-direction:column;gap:6px}
    label{font-size:12px;color:var(--muted)}
    input,textarea{width:100%;background:#0f0f13;color:var(--fg);border:1px solid var(--border);border-radius:10px;padding:10px;font-size:14px;outline:none}
    textarea{min-height:140px;font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, "Liberation Mono", monospace;line-height:1.35}
    button{background:var(--accent);color:#fff;border:none;border-radius:10px;padding:10px 14px;font-weight:700;cursor:pointer}
    .muted{color:var(--muted);font-size:12px}
    .banner{padding:10px 12px;border-radius:10px;margin-bottom:10px}
    .banner.error{background:#3a0c12;border:1px solid #6b0f1a;color:#ffd3da}
    pre{background:#0f0f13;border:1px solid var(--border);padding:12px;border-radius:10px;overflow:auto;max-height:360px;white-space:pre-wrap}
    details{border:1px solid var(--border);border-radius:10px;margin-bottom:8px;background:#0f0f13}
    details>summary{cursor:pointer;padding:10px 12px;color:var(--fg)}
    details pre{margin:0;border:none;border-top:1px solid var(--border);border-radius:0 0 10px 10px}
    .cols{display:grid;grid-template-columns:2fr 1fr;gap:16px}
    @media (max-width:900px){.cols{grid-template-columns:1fr}}
    ul{margin:6px 0;padding-left:18px}
    .row-inline{display:flex;align-items:center;gap:8px}
    .file-actions{display:flex;gap:8px;padding:8px 12px}
    .ghost{background:transparent;border:1px solid var(--border);color:var(--fg)}
    .checks{display:flex;gap:12px;align-items:center;flex-wrap:wrap;font-size:13px;color:var(--muted)}
    .checks label{display:flex;gap:6px;align-items:center}
  </style>
</head>
<body>
  <header>
    <h1>legacy.exe</h1>
    <div class="sub">compare</div>
  </header>

  <main>
    <section class="panel">
      <div id="api-offline" class="banner error" style="display:none">API offline (http://127.0.0.1:8000)</div>
      <div class="grid">
        <div class="row">
          <label>API base (backend)</label>
          <input id="api-base" placeholder="http://127.0.0.1:8000" value="http://127.0.0.1:8000" />
        </div>

        <div class="row">
          <label>LLM API URL</label>
          <input id="llm-url" placeholder="https://api.groq.com/openai/v1/chat/completions  •  https://generativelanguage.googleapis.com/v1beta" />
        </div>
        <div class="row">
          <label>LLM API Key</label>
          <input id="llm-key" type="password" placeholder="chave do provedor (Groq ou Gemini)" />
        </div>
        <div class="row">
          <label>LLM Model</label>
          <input id="model" placeholder="llama-3.1-8b-instant  •  gemma-3-27b-it" />
        </div>

        <div class="row">
          <label>repo</label>
          <input id="repo" placeholder="org/repo" />
        </div>
        <div class="row">
          <label>branch</label>
          <input id="branch" placeholder="main" value="main" />
        </div>
        <div class="row">
          <label>extensões</label>
          <input id="exts" placeholder=".py,.js,.java" value=".py,.js,.java" />
        </div>
        <div class="row">
          <label>paths</label>
          <input id="paths" placeholder="/ (tudo) • ou src/,app/" />
        </div>

        <div class="row">
          <label>GitHub PAT (opcional)</label>
          <input id="pat" type="password" placeholder="token para repos privados" />
        </div>
      </div>

      <div class="checks" style="margin-top:8px">
        <label><input type="checkbox" id="allow-placeholders"> allow placeholders</label>
        <label><input type="checkbox" id="debug-echo-raw"> debug echo raw</label>
      </div>

      <div class="row" style="margin-top:8px">
        <label>requisitos</label>
        <textarea id="reqs" placeholder="Sem codigo duplicado!"></textarea>
      </div>

      <div class="row-inline" style="margin-top:10px">
        <button id="run">comparar</button>
        <button id="download-all" class="ghost">baixar todos</button>
        <span class="muted" id="status"></span>
      </div>
    </section>

    <section class="panel">
      <div class="cols">
        <div>
          <h3 style="margin:8px 0;color:var(--muted)">Relatório</h3>
          <pre id="report"><code></code></pre>
        </div>
        <div>
          <h3 style="margin:8px 0;color:var(--muted)">Resumo</h3>
          <ul id="summary"></ul>
        </div>
      </div>

      <h3 style="margin:12px 0;color:var(--muted)">Arquivos Atualizados</h3>
      <div id="files"></div>

      <h3 style="margin:12px 0;color:var(--muted)">Raw (debug)</h3>
      <pre id="raw"><code></code></pre>
    </section>
  </main>

  <script src="./script.js" type="module"></script>
</body>
</html>
```

## frontend/script.js

```javascript
// minimal compare-only client

const $ = (q) => document.querySelector(q);
const setText = (node, text) => (node.textContent = text ?? "");
const bullets = (node, items) => {
  node.innerHTML = "";
  (items || []).slice(0, 64).forEach((x) => {
    const li = document.createElement("li");
    li.textContent = String(x);
    node.appendChild(li);
  });
};
const copyText = (t) => navigator.clipboard?.writeText(t).catch(()=>{});
function download(name, text){
  const a=document.createElement("a");
  a.href=URL.createObjectURL(new Blob([text],{type:"text/plain"}));
  a.download=name||"arquivo.txt"; a.click(); URL.revokeObjectURL(a.href);
}
function parseCSV(str) {
  return String(str || "")
    .split(",")
    .map((s) => s.trim())
    .filter(Boolean);
}

// Strong steering so the model avoids placeholders:
const PROMPT_BASE = `
- Responda SOMENTE JSON válido UTF-8, sem markdown.
- Não use placeholders como "conteúdo do ..." ou "resultado disponível em".
- Preencha "report" com 3–10 bullets técnicos e acionáveis (português).
- "summary": lista de 3–8 decisões, riscos ou próximos passos.
- "updated_files": crie apenas arquivos REAIS do projeto; evite duplicar arquivos existentes sem necessidade.
- Se for Python, os arquivos devem terminar com .py e conter código válido (ex.: imports, def, if __name__).
- Evite criar pastas artificiais (ex.: "resultados/v1/").
- Se não houver nada para mudar, mantenha "updated_files": [] e explique o porquê no "report".
`.trim();

let lastFiles = [];

function renderFiles(files) {
  lastFiles = files || [];
  const root = $("#files");
  root.innerHTML = "";
  (lastFiles).forEach((f) => {
    const details = document.createElement("details");
    const sum = document.createElement("summary");
    sum.textContent = f.path || "(sem nome)";

    const actions = document.createElement("div");
    actions.className = "file-actions";
    const bCopy = document.createElement("button");
    bCopy.className = "ghost";
    bCopy.textContent = "copiar";
    bCopy.addEventListener("click", (e)=>{ e.preventDefault(); copyText(f.content||""); });

    const bDl = document.createElement("button");
    bDl.className = "ghost";
    bDl.textContent = "baixar";
    bDl.addEventListener("click", (e)=>{ e.preventDefault(); download(f.path||"arquivo.txt", f.content||""); });

    actions.appendChild(bCopy);
    actions.appendChild(bDl);

    const pre = document.createElement("pre");
    const code = document.createElement("code");
    code.textContent = f.content || "";
    pre.appendChild(code);

    details.appendChild(sum);
    details.appendChild(actions);
    details.appendChild(pre);
    root.appendChild(details);
  });
}

function offlineBanner(show) {
  $("#api-offline").style.display = show ? "block" : "none";
}

async function runCompare() {
  const API_BASE = $("#api-base").value.trim() || "http://127.0.0.1:8000";

  // LLM (provider-agnostic)
  const llm_api_url = $("#llm-url").value.trim();       // Groq OpenAI endpoint OR Gemini v1beta base
  const llm_api_key = $("#llm-key").value.trim();
  const model       = $("#model").value.trim();

  const repo = $("#repo").value.trim();
  const branch = $("#branch").value.trim() || "main";
  const include_ext = parseCSV($("#exts").value);
  const raw_paths = parseCSV($("#paths").value);
  const include_paths = raw_paths.length ? raw_paths : ["/"]; // default: whole repo
  const requisitos = $("#reqs").value;
  const github_pat = $("#pat").value.trim() || null;

  const allow_placeholders = $("#allow-placeholders").checked;
  const debug_echo_raw = $("#debug-echo-raw").checked;

  const debug_no_llm = !(llm_api_key && model && llm_api_url);

  $("#status").textContent = "enviando...";
  offlineBanner(false);
  setText($("#report code"), "");
  $("#summary").innerHTML = "";
  $("#files").innerHTML = "";
  setText($("#raw code"), "");

  try {
    const r = await fetch(`${API_BASE}/compare`, {
      method: "POST",
      headers: { "content-type": "application/json" },
      body: JSON.stringify({
        repo,
        branch,
        include_ext,
        include_paths,
        requisitos,
        github_pat,
        debug_no_llm,
        // generic LLM config
        llm_api_url,
        llm_api_key,
        model,
        // steering + toggles
        prompt_base: PROMPT_BASE,
        allow_placeholders,
        debug_echo_raw,
      }),
    });

    const text = await r.text();
    if (!r.ok) {
      let msg = text;
      try {
        const j = JSON.parse(text);
        msg = j.detail || text;
      } catch {}
      throw new Error(msg);
    }

    const j = JSON.parse(text);
    setText($("#report code"), j.report || "");
    bullets($("#summary"), j.summary || []);
    renderFiles(j.updated_files || []);
    if (j.raw) setText($("#raw code"), j.raw);
    $("#status").textContent = "ok";
  } catch (e) {
    $("#status").textContent = "erro";
    offlineBanner(true);
    setText($("#report code"), "");
    bullets($("#summary"), [`falha: ${String(e).slice(0, 400)}`]);
    $("#files").innerHTML = "";
    setText($("#raw code"), "");
    lastFiles = [];
  }
}

document.addEventListener("DOMContentLoaded", () => {
  $("#run").addEventListener("click", runCompare);
  $("#download-all").addEventListener("click", ()=>{
    for (const f of lastFiles) download(f.path||"arquivo.txt", f.content||"");
  });

  // quick deep-linking
  const q = new URLSearchParams(location.search);
  if (q.get("api")) $("#api-base").value = q.get("api");
  if (q.get("llm")) $("#llm-url").value = q.get("llm");
  if (q.get("llm_key")) $("#llm-key").value = q.get("llm_key");
  if (q.get("model")) $("#model").value = q.get("model");
  if (q.get("repo")) $("#repo").value = q.get("repo");
  if (q.get("branch")) $("#branch").value = q.get("branch");
  if (q.get("exts")) $("#exts").value = q.get("exts");
  if (q.get("paths")) $("#paths").value = q.get("paths");
  if (q.get("allow")) $("#allow-placeholders").checked = q.get("allow") === "1";
  if (q.get("raw")) $("#debug-echo-raw").checked = q.get("raw") === "1";
  if (q.get("autorun") === "1") runCompare();
});
```

## old/index.html

```html
<!doctype html>
<html lang="pt-br">
<head>
  <meta charset="utf-8">
  <title>legacy.exe</title>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./styles.css">
</head>
<body>
  <header>
    <h1>legacy.exe</h1>
    <div class="sub">byo-key client</div>
  </header>

  <main>
    <section class="panel">
      <div class="grid4">
        <div class="row">
          <label>linguagem</label>
          <select id="language">
            <option value="java">java</option>
            <option value="python">python</option>
            <option value="javascript">javascript</option>
            <option value="csharp">csharp</option>
          </select>
        </div>
        <div class="row">
          <label>provider</label>
          <select id="provider">
            <option value="gemini">gemini</option>
            <option value="openai">openai</option>
          </select>
        </div>
        <div class="row">
          <label>model</label>
          <input id="model" placeholder="auto">
        </div>
        <div class="row">
          <label>api key</label>
          <input id="apikey" type="password" placeholder="cole sua chave">
          <button id="remember" class="toggle">remember key</button>
        </div>
      </div>

      <div class="row code-wrap collapsed">
        <label>código legado</label>
        <textarea id="legacy" placeholder="cole aqui" rows="20"></textarea>
        <button id="btn-expand" class="ghost" aria-expanded="false">mostrar mais</button>
      </div>

      <div class="actions below">
        <button id="btn-refactor">refatorar</button>
        <button id="btn-sample">sample</button>
        <div class="muted" id="status"></div>
      </div>
    </section>

    <section class="panel output">
      <div class="columns">
        <div>
          <h3>antes</h3>
          <pre id="before"><code></code></pre>
        </div>
        <div>
          <h3>depois</h3>
          <pre id="after"><code></code></pre>
        </div>
      </div>

      <div class="columns meta">
        <div>
          <h3>diff</h3>
          <pre id="diff"><code></code></pre>
        </div>
        <div>
          <h3>notas</h3>
          <ul id="notes"></ul>
          <h3>summary</h3>
          <ul id="summary"></ul>
          <div class="save">
            <button id="btn-download">baixar código</button>
          </div>
        </div>
      </div>
    </section>
  </main>

  <div id="overlay">
    <div class="loader"></div>
    <div class="msg">refatorando...</div>
  </div>

  <script type="module" src="./js/app.js"></script>
</body>
</html>
```

## old/js/api_byo.js

````javascript
// -------- prompts --------
function sysRefactor(lang){
  return `Você é um agente de modernização de código.
Responda SOMENTE JSON válido:
{"code":"<código COMPLETO>", "summary":"<lista ou string>", "notes":"<lista ou string>"}.
NADA fora do JSON. Linguagem alvo: ${lang}.`;
}
function sysReview(lang){
  return `Você é revisor. Dado {original, refactored}, devolva SOMENTE:
{"code":"<código FINAL>", "notes":"<lista ou string>"}.
NADA fora do JSON. Linguagem: ${lang}.`;
}

// -------- util --------
function asArray(x){
  if (Array.isArray(x)) return x;
  if (x == null) return [];
  return String(x).split(/\r?\n|[;•]+/).map(s=>s.trim()).filter(Boolean);
}
function looksLikeCode(s, lang){
  if (!s) return false;
  const t = String(s).trim();
  if (t.length < 10) return false;              // evita "200", "ok"
  if (!/[;\n{}()=]/.test(t)) return false;      // precisa ter “cara” de código
  const L = (lang||"").toLowerCase();
  const KW = {
    java: /\b(class|public|static|void|import|try|catch|package)\b/,
    python: /\b(def|import|class|return|with|try|except)\b/,
    javascript: /\b(function|const|let|import|export|class|=>)\b/,
    csharp: /\b(namespace|class|using|public|static|void)\b/
  };
  const rx = KW[L] || /./;
  return rx.test(t);
}
function normalize(obj){
  if (obj == null || typeof obj !== "object")
    return { code:"", summary:[], notes: obj==null ? [] : [String(obj)] };
  const code = obj.code != null ? String(obj.code) : "";
  const summary = asArray(obj.summary);
  const notes = asArray(obj.notes);
  return { code, summary, notes };
}
function safeJSON(s){
  // tenta direto
  try{ return normalize(JSON.parse(s)) }catch{}
  // tenta bloco ```json
  const m = String(s).match(/```(?:json)?\s*([\s\S]*?)```/i);
  if (m){ try{ return normalize(JSON.parse(m[1])) }catch{} }
  // tudo falhou → devolve em notes
  return { code:"", summary:[], notes:String(s||"") };
}

// -------- providers --------
async function callOpenAI({apiKey,model,messages}){
  const r = await fetch("https://api.openai.com/v1/chat/completions",{
    method:"POST",
    headers:{authorization:`Bearer ${apiKey}`,"content-type":"application/json"},
    body:JSON.stringify({model:model||"gpt-4o-mini",temperature:0.2,messages})
  });
  const t = await r.text();
  if(!r.ok) throw new Error(t);
  const j = JSON.parse(t);
  return j.choices?.[0]?.message?.content ?? "";
}
function toGemini(messages){
  // Gemini 1.5 aceita responseMimeType = "application/json"
  return messages.map(m=>({role:m.role==="system"?"user":m.role,parts:[{text:String(m.content)}]}));
}
async function callGemini({apiKey,model,messages}){
  const r = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/${model||"gemini-1.5-flash"}:generateContent?key=${apiKey}`,
    {
      method:"POST",
      headers:{"content-type":"application/json"},
      body:JSON.stringify({
        contents: toGemini(messages),
        generationConfig: {
          temperature: 0.2,
          responseMimeType: "application/json"   // força JSON puro
        }
      })
    }
  );
  const t = await r.text();
  if(!r.ok) throw new Error(t);
  const j = JSON.parse(t);
  // quando responseMimeType=JSON, vem em parts[0].text como string JSON
  return j.candidates?.[0]?.content?.parts?.map(p=>p.text||"").join("") ?? "";
}

// -------- main --------
export async function refactorBYO({provider,model,apiKey,code,language}){
  const m1 = [
    { role:"system", content: sysRefactor(language) },
    { role:"user",   content: `original:\n\`\`\`${language}\n${code}\n\`\`\`` }
  ];
  const raw1 = provider==="openai"
    ? await callOpenAI({apiKey,model,messages:m1})
    : await callGemini({apiKey,model,messages:m1});
  const j1 = safeJSON(raw1);             // {code, summary[], notes[]}

  const m2 = [
    { role:"system", content: sysReview(language) },
    { role:"user",   content: JSON.stringify({original:code,refactored:j1.code||""}) }
  ];
  const raw2 = provider==="openai"
    ? await callOpenAI({apiKey,model,messages:m2})
    : await callGemini({apiKey,model,messages:m2});
  const j2 = safeJSON(raw2);             // {code, notes[]}

  // valida “cara de código”
  const code2ok = looksLikeCode(j2.code, language);
  const code1ok = looksLikeCode(j1.code, language);

  const finalCode = code2ok ? j2.code : (code1ok ? j1.code : "");
  const finalNotes = [
    ...(j2.notes||[]),
    ...(code2ok ? [] : ["review sem código válido"]),
    ...(code1ok ? [] : ["refactor sem código válido"])
  ].filter(Boolean);

  return { code: finalCode, summary: j1.summary||[], notes: finalNotes };
}
````

## old/js/app.js

```javascript
import { refactorBYO } from "./api_byo.js"
import { saveConfig, loadConfig } from "./config.js"
import { el } from "./util.js"
import {
  bindSample, bindRefactor, bindRemember, readInputs, setInputs,
  showBefore, showAfter, showMeta, bindDownload, overlay,
  mountState, showError, status, bindExpand
} from "./ui.js"

const state = mountState()
function setLegacy(v){ el("#legacy").value = v }

const cfg = loadConfig()
setInputs(cfg||{})

bindSample(setLegacy)
bindRemember()
bindExpand()

bindRefactor(async ()=>{
  const input = readInputs()
  if(!input.code.trim()) return
  if(!input.apiKey) { showError("api key ausente"); return }
  if(input.save) saveConfig({provider:input.provider,model:input.model,apiKey:input.apiKey,save:true})

  showBefore(input.code)
  overlay(true); status("rodando...")
  const t0 = performance.now()

  try{
    const r = await refactorBYO({
      provider: input.provider,
      model: input.model,
      apiKey: input.apiKey,
      code: input.code,
      language: input.language
    })
    if(!(r.code && r.code.trim())){
      showError(r.notes || "falha na refatoração")
    }else{
      showAfter(r.code||"")
      state.setAfter(r.code||"")
      showMeta({ before: input.code, after: r.code||"", notes: r.notes||[], summary: r.summary||[] })
    }
  }catch(e){
    showError(String(e))
  }finally{
    const ms = Math.round(performance.now()-t0)
    overlay(false); status(`${input.provider} · ${input.model||"auto"} · ${ms}ms`)
  }
})

bindDownload(()=>state.getAfter())
```

## old/js/config.js

```javascript
const K="legacyexe.v1"
export function saveConfig({provider,model,apiKey,save}){
  try{ localStorage.setItem(K, JSON.stringify({provider,model,apiKey,save:!!save})) }catch{}
}
export function loadConfig(){
  try{ return JSON.parse(localStorage.getItem(K)||"{}") }catch{ return {} }
}
export function hasSaved(){ try{ return !!(JSON.parse(localStorage.getItem(K)||"{}").apiKey) }catch{ return false } }
```

## old/js/diff.js

```javascript
function lcsLines(A,B){
  const m=A.length,n=B.length,dp=Array.from({length:m+1},()=>Array(n+1).fill(0))
  for(let i=1;i<=m;i++)for(let j=1;j<=n;j++)
    dp[i][j]=A[i-1]===B[j-1]?dp[i-1][j-1]+1:Math.max(dp[i-1][j],dp[i][j-1])
  const out=[];let i=m,j=n
  while(i>0&&j>0){
    if(A[i-1]===B[j-1]){out.push({t:" ",v:A[i-1]});i--;j--}
    else if(dp[i-1][j]>=dp[i][j-1]){out.push({t:"-",v:A[i-1]});i--}
    else{out.push({t:"+",v:B[j-1]});j--}
  }
  while(i>0){out.push({t:"-",v:A[i-1]});i--}
  while(j>0){out.push({t:"+",v:B[j-1]});j--}
  return out.reverse()
}
export function unifiedDiff(a,b){
  const A=String(a||"").split("\n"),B=String(b||"").split("\n")
  const seq=lcsLines(A,B)
  const lines = ["--- antes","+++ depois",...seq.map(x=>`${x.t} ${x.v}`)]
  return lines.join("\n")
}
```

## old/js/ui.js

```javascript
import { el, setText, bulletsToList, download } from "./util.js"
import { unifiedDiff } from "./diff.js"

// ---- remember key ----
let remember = false
export function bindRemember(){
  const btn = el("#remember")
  btn.addEventListener("click",()=>{
    remember = !remember
    btn.classList.toggle("active", remember)
    btn.textContent = remember ? "remember key ✓" : "remember key"
  })
}
export function shouldRemember(){ return remember }
export function setRemember(v){
  remember = !!v
  const btn = el("#remember")
  btn.classList.toggle("active", remember)
  btn.textContent = remember ? "remember key ✓" : "remember key"
}

// ---- expand/collapse editor: clamp ~20 linhas e auto-grow sem scrollbar ----
function setClampHeight(container, lines=20){
  const ta = container.querySelector("textarea")
  const cs = getComputedStyle(ta)
  const lh = parseFloat(cs.lineHeight || "18")
  const py = parseFloat(cs.paddingTop||"12")+parseFloat(cs.paddingBottom||"12")
  const max = Math.round(lh*lines + py)
  container.style.setProperty("--ta-max", `${max}px`)
}
function autosize(ta){
  ta.style.height = "auto"
  ta.style.height = ta.scrollHeight + "px"
}
export function bindExpand(){
  const wrap = el(".code-wrap")
  const ta   = el("#legacy")
  const btn  = el("#btn-expand")

  const sync = () => {
    const collapsed = wrap.classList.contains("collapsed")
    btn.textContent = collapsed ? "mostrar mais" : "mostrar menos"
    btn.setAttribute("aria-expanded", String(!collapsed))
    if (collapsed){
      // volta a usar o clamp controlado por CSS
      setClampHeight(wrap, 20)
      ta.style.height = ""
    } else {
      // cresce até caber todo conteúdo
      autosize(ta)
    }
  }

  btn.addEventListener("click", ()=>{
    wrap.classList.toggle("collapsed")
    sync()
  })

  // enquanto digita, só autosize quando expandido
  ta.addEventListener("input", ()=>{ if(!wrap.classList.contains("collapsed")) autosize(ta) })

  window.addEventListener("resize", sync)

  // init
  wrap.classList.add("collapsed")
  setClampHeight(wrap, 20)
  sync()
}

// ---- misc UI helpers ----
export function bindSample(setLegacy){
  el("#btn-sample").addEventListener("click",()=>{ 
    setLegacy(`import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.Statement;

public class LegacyApp {

    public static void main(String[] args) {
        Connection conn = null;
        Statement stmt = null;
        ResultSet rs = null;

        try {
            // Driver JDBC carregado manualmente (pré-Java 6)
            Class.forName("com.mysql.jdbc.Driver");

            conn = DriverManager.getConnection(
                "jdbc:mysql://localhost:3306/legacydb",
                "root",
                "1234"
            );

            stmt = conn.createStatement();
            rs = stmt.executeQuery("SELECT id, nome FROM usuarios");

            while (rs.next()) {
                int id = rs.getInt("id");
                String nome = rs.getString("nome");
                System.out.println("ID: " + id + " Nome: " + nome);
            }

        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            // Fecha manualmente cada recurso (sem try-with-resources)
            try { if (rs != null) rs.close(); } catch (Exception e) {}
            try { if (stmt != null) stmt.close(); } catch (Exception e) {}
            try { if (conn != null) conn.close(); } catch (Exception e) {}
        }
    }
}
}`) })
}
export function bindRefactor(onRun){ el("#btn-refactor").addEventListener("click", onRun) }
export function readInputs(){
  return {
    language: el("#language").value,
    provider: el("#provider").value,
    model: el("#model").value.trim() || undefined,
    apiKey: el("#apikey").value.trim(),
    code: el("#legacy").value,
    save: shouldRemember()
  }
}
export function setInputs({provider,model,apiKey,save}){
  if(provider) el("#provider").value = provider
  if(model) el("#model").value = model
  if(apiKey) el("#apikey").value = apiKey
  setRemember(!!save || !!apiKey)
}
export function showBefore(code){ setText(el("#before code"), code||"") }
export function showAfter(code){ setText(el("#after code"), code||"") }
export function showMeta({before, after, notes, summary}){
  setText(el("#diff code"), unifiedDiff(before, after))
  bulletsToList(el("#notes"), notes)
  bulletsToList(el("#summary"), summary)
}
export function showError(msg){
  setText(el("#after code"), "")
  bulletsToList(el("#notes"), [`erro: ${msg}`])
}
export function bindDownload(getAfter){
  el("#btn-download").addEventListener("click",()=>{
    const out = getAfter()
    if(!out) return
    download("legacy_refatorado.txt", out)
  })
}
export function overlay(v){ el("#overlay").style.display = v ? "flex" : "none" }
export function status(t){ el("#status").textContent = t||"" }
export function mountState(){ let after=""; return { setAfter:v=>after=v, getAfter:()=>after } }
```

## old/js/util.js

```javascript
export function el(q){return document.querySelector(q)}
export function setText(node, text){node.textContent = text}
export function download(filename, text){
  const a = document.createElement("a")
  a.href = URL.createObjectURL(new Blob([text],{type:"text/plain"}))
  a.download = filename
  a.click()
  URL.revokeObjectURL(a.href)
}
export function bulletsToList(node, s){
  node.innerHTML = ""
  if(!s) return
  const arr = Array.isArray(s) ? s : String(s).split(/[\r\n;•-]+/).map(x=>x.trim()).filter(Boolean)
  for(const p of arr.slice(0,12)){
    const li = document.createElement("li")
    li.textContent = p
    node.appendChild(li)
  }
}
```

## README.md

```markdown
## **roteiro**

### **\[0:00 – 0:20] – INTRO**

* tela preta, logo glitch “LEGACY.EXE”.

* narração:

  > “todo sistema carrega fantasmas. código legado. caro, lento, trava inovação. as empresas sangram bilhões todo ano nisso. hoje a gente mata esse monstro.”

---

### **\[0:20 – 0:50] – O PROBLEMA**

* mostra um código velho, feio, cheio de gambiarra.

* narração:

  > “a manutenção de código legado é o câncer da TI. demanda especialista que nem existe mais, atrasa tudo e custa caro. a ford e qualquer corporação gigante vivem isso todo dia.”

* corta: “solução antiga? reescrever na unha. meses, anos, burnout.”

---

### **\[0:50 – 1:20] – APRESENTAÇÃO DA SOLUÇÃO**

* mostra a tela da **web ui**. simples, direta. campo “colar código”. botão vermelho: **REFATORAR**.
* narração:

  > “essa é a nossa arma: LEGACY.EXE. uma interface mínima, mas com um motor absurdo por trás. com base em IA generativa, com prompts otimizados e pipeline multi-agent. você cola código legado… e ele volta vivo. moderno. limpo. pronto pra produção.”

---

### **\[1:20 – 2:10] – DEMONSTRAÇÃO**

* colar um código legado (java antigo, por exemplo).

* clicar no botão.

* mostrar **output refatorado** com comentários das mudanças.

* narração:

  > “em segundos, LEGACY.EXE analisa, reconstrói e entrega um refactor absurdo. não é só GPT puro, é um processo: prompt tunado, validação automática, múltiplos agentes discutindo a solução, e o resultado final cai direto na sua mão.”

* split-screen: **antes** (gambiarra) vs **depois** (código limpo).

---

### **\[2:10 – 2:40] – PROPOSTA DE VALOR**

* narração sobre fundo com slides minimalistas:

  > “o que antes levava semanas, agora leva segundos.
  > menos retrabalho.
  > menos dependência de especialista em linguagem morta.
  > mais velocidade pro negócio.
  > LEGACY.EXE corta custo e tempo, libera times pra inovar.”

---

### **\[2:40 – 3:00] – FECHAMENTO**

* câmera volta pra tela da UI, logo glitch LEGACY.EXE.

* voz final, fria, direta:

  > “esse é o futuro. LEGACY.EXE: LEGACY ENDS HERE.
  > a ford pediu modernização. a gente entregou revolução.”

* fade out.
```

## reqs.txt

```text
Refatore para:
- evitar código duplicado;
- extrair funções utilitárias em comparador.py;
- adicionar checagem de extensões suportadas;
- retornar códigos de saída adequados;
- manter compatibilidade com tests/.
```

## server/app/main.py

````python
import os, base64, logging, fnmatch, time, re
from typing import List, Optional, Dict, Any, Tuple
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from github import Github, GithubIntegration
from github.GithubException import GithubException
from dotenv import load_dotenv
import requests

load_dotenv()

ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "*")
allow_origins = ["*"] if ALLOWED_ORIGINS.strip() == "*" else [
    o.strip() for o in ALLOWED_ORIGINS.split(",") if o.strip()
]
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=allow_origins,
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

log = logging.getLogger("uvicorn.error")

# =============================================================================
# Models
# =============================================================================
class CompareIn(BaseModel):
    repo: str
    branch: Optional[str] = "main"
    include_ext: List[str] = Field(default_factory=lambda: [".py", ".js", ".java"])
    include_paths: List[str] = Field(default_factory=list)
    requisitos: str
    prompt_base: Optional[str] = None
    max_files: int = 200
    max_bytes: int = 800_000
    debug_no_llm: bool = False

    # Generic LLM config
    llm_api_url: Optional[str] = None
    llm_api_key: Optional[str] = None
    model: Optional[str] = None

    # Back-compat (prefer generic fields above)
    groq_api_key: Optional[str] = None

    # Optional GitHub App BYOK
    github_pat: Optional[str] = None
    github_app_id: Optional[str] = None
    github_installation_id: Optional[str] = None
    github_private_key_pem_b64: Optional[str] = None

    # NEW: debugging / filtering toggles
    debug_echo_raw: bool = False
    allow_placeholders: bool = False

class FileOut(BaseModel):
    path: str
    content: str

class CompareOut(BaseModel):
    report: str
    summary: List[str]
    updated_files: List[FileOut]
    raw: Optional[str] = None

# =============================================================================
# GitHub helpers
# =============================================================================
def gh_via_pat(pat: str) -> Github:
    return Github(pat, timeout=30)

def gh_via_app(app_id: str, installation_id: str, private_key_pem: str) -> Github:
    integ = Github(app_id, private_key_pem)
    token = integ.get_access_token(int(installation_id)).token
    return Github(token, timeout=30)

def gh_client(body: CompareIn) -> Github:
    if body.github_pat:
        return gh_via_pat(body.github_pat)
    if body.github_app_id and body.github_installation_id and body.github_private_key_pem_b64:
        pem = base64.b64decode(body.github_private_key_pem_b64).decode("utf-8")
        return gh_via_app(body.github_app_id, body.github_installation_id, pem)
    app_id = os.getenv("GITHUB_APP_ID")
    inst_id = os.getenv("GITHUB_INSTALLATION_ID")
    key_path = os.getenv("GITHUB_PRIVATE_KEY_PATH")
    if app_id and inst_id and key_path and os.path.exists(key_path):
        with open(key_path, "r") as f:
            pem = f.read()
        return gh_via_app(app_id, inst_id, pem)
    return Github(timeout=30)

# =============================================================================
# Filters
# =============================================================================
def _norm_exts(exts: List[str]) -> List[str]:
    out = []
    for e in exts or []:
        e = e.strip().lower()
        if not e:
            continue
        if e == "*":
            return []  # wildcard = no filter
        if not e.startswith("."):
            e = "." + e
        out.append(e)
    return out

def _norm_path(p: str) -> str:
    out = (p or "").replace("\\", "/")
    while "//" in out:
        out = out.replace("//", "/")
    return out

def _path_matches_any(path: str, patterns: List[str]) -> bool:
    if not patterns:
        return True
    if any(p.strip() == "/" for p in patterns):
        return True
    p_norm = _norm_path(path).lstrip("/")
    for raw in patterns:
        pat = _norm_path(raw).lstrip("/")
        if any(ch in pat for ch in ["*", "?", "["]):
            if fnmatch.fnmatch(p_norm, pat):
                return True
        if p_norm.startswith(pat):
            return True
    return False

def file_allowed(path: str, exts: List[str], include_paths: List[str]) -> bool:
    p = _norm_path(path)
    exts_norm = _norm_exts(exts)
    if exts_norm and not any(p.lower().endswith(e) for e in exts_norm):
        return False
    if not _path_matches_any(p, include_paths):
        return False
    return True

def extract_numbered_code(
    g: Github,
    repo_name: str,
    branch: str,
    include_ext: List[str],
    include_paths: List[str],
    max_files: int,
    max_bytes: int,
) -> Tuple[str, int, int]:
    repo, ref = _repo_and_ref(g, repo_name, branch)
    contents = repo.get_contents("", ref=ref)
    chunks: List[str] = []
    nfiles = 0
    nbytes = 0

    while contents:
        it = contents.pop(0)
        if it.type == "dir":
            dir_path = _norm_path(it.path).rstrip("/") + "/"
            if include_paths and not _path_matches_any(dir_path, include_paths):
                keep = any(_norm_path(p).lstrip("/").startswith(dir_path) for p in include_paths)
                if not keep:
                    continue
            contents.extend(repo.get_contents(it.path, ref=ref))
            continue

        if not file_allowed(it.path, include_ext, include_paths):
            continue

        try:
            blob = it.decoded_content
        except Exception:
            continue

        nfiles += 1
        nbytes += len(blob)
        if nfiles > max_files or nbytes > max_bytes:
            break

        snippet = blob.decode(errors="ignore")
        lines = snippet.splitlines()[:800]
        snippet = "\n".join(lines)
        numbered = "\n".join(f"{i+1}: {line}" for i, line in enumerate(snippet.splitlines()))
        chunks.append(f"### {it.path}\n{numbered}")

    return ("\n\n".join(chunks), nfiles, nbytes)

# =============================================================================
# LLM glue (OpenAI-compatible + Gemini)
# =============================================================================
REF_PROMPT_HDR = (
    "Você é um engenheiro sênior. RETORNE SOMENTE JSON válido em UTF-8, sem markdown, sem comentários.\n"
    "Formato obrigatório: {\"report\":\"...\",\"summary\":[\"...\"],\"updated_files\":[{\"path\":\"...\",\"content\":\"...\"}]}\n"
)

def safe_json(s: str) -> Dict[str, Any]:
    import json
    s = (s or "").strip()
    try:
        j = json.loads(s)
        if isinstance(j, dict):
            return j
    except Exception:
        pass
    m = re.search(r"```(?:json)?\s*([\s\S]*?)```", s or "", re.I)
    if m:
        try:
            j = json.loads(m.group(1))
            if isinstance(j, dict):
                return j
        except Exception:
            pass
    return {"report": "", "summary": [], "updated_files": [], "_raw": s}

def _is_gemini_url(api_url: str) -> bool:
    return "generativelanguage.googleapis.com" in (api_url or "")

def _openai_chat(api_url: str, api_key: str, model: str, messages: list, *, temperature=0.2, top_p=0.9) -> str:
    url = api_url or "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}"}
    payload = {"model": model, "messages": messages, "temperature": temperature, "top_p": top_p}
    for attempt in range(3):
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        status = getattr(r, "status_code", 200)
        if status == 429:
            delay = float(r.headers.get("Retry-After", 1.5 * (attempt + 1)))
            time.sleep(delay)
            continue
        if status >= 400:
            r.raise_for_status()
        j = r.json()
        return j["choices"][0]["message"]["content"]
    r.raise_for_status()
    raise RuntimeError("unexpected")

def _gemini_generate(api_base: str, api_key: str, model: str, user_text: str, *, temperature=0.2, top_p=0.9) -> str:
    base = api_base.rstrip("/")
    endpoint = f"{base}/models/{model}:generateContent?key={api_key}"
    payload = {
        "contents": [ {"role": "user", "parts": [{"text": user_text}]} ],
        "generationConfig": {"temperature": temperature, "topP": top_p}
    }
    for attempt in range(3):
        r = requests.post(endpoint, json=payload, timeout=60)
        status = getattr(r, "status_code", 200)
        if status == 429:
            delay = float(r.headers.get("Retry-After", 1.5 * (attempt + 1)))
            time.sleep(delay)
            continue
        if status >= 400:
            r.raise_for_status()
        j = r.json()
        cands = (j or {}).get("candidates") or []
        if not cands:
            return ""
        parts = (cands[0].get("content") or {}).get("parts") or []
        out = []
        for p in parts:
            t = p.get("text", "")
            if t:
                out.append(t)
        return "\n".join(out).strip()
    r.raise_for_status()
    raise RuntimeError("unexpected")

def _call_llm_text(api_url: str, api_key: str, model: str, messages: list) -> str:
    if _is_gemini_url(api_url):
        # flatten to one "user" turn for Gemini
        buf = []
        for m in messages:
            role = m.get("role") or "user"
            content = m.get("content") or ""
            if role == "system":
                buf.append(f"[SYSTEM]\n{content}")
            else:
                buf.append(content)
        user_text = "\n\n".join(buf)
        return _gemini_generate(api_url, api_key, model, user_text)
    else:
        return _openai_chat(api_url, api_key, model, messages)

def call_llm_json(api_url: str, api_key: str, model: str, messages: list) -> Tuple[Dict[str, Any], str]:
    text = _call_llm_text(api_url, api_key, model, messages)
    return safe_json(text), text

def llm_refactor_review(api_url: str, api_key: str, requisitos: str, codigo: str, prompt_base: Optional[str], model: str) -> Tuple[Dict[str, Any], str, str]:
    base = prompt_base or ""
    m1 = [
        {"role": "system", "content": REF_PROMPT_HDR + base},
        {"role": "user", "content": f"=== REQUISITOS ===\n{requisitos}\n\n=== CODIGO NUMERADO ===\n{codigo}"},
    ]
    j1, raw1 = call_llm_json(api_url, api_key, model, m1)

    repair_instr = (
        "Valide que o JSON possui as chaves 'report', 'summary'(lista), 'updated_files'(lista de objetos com 'path' e 'content').\n"
        "Se algo faltar, corrija. Retorne SOMENTE JSON válido."
    )
    m2 = [
        {"role": "system", "content": REF_PROMPT_HDR + repair_instr},
        {"role": "user", "content": str(j1)},
    ]
    j2, raw2 = call_llm_json(api_url, api_key, model, m2)

    def looks_ok(j):
        return isinstance(j.get("updated_files"), list) and isinstance(j.get("summary"), list) and isinstance(j.get("report"), str)

    final = j2 if looks_ok(j2) else j1
    final.setdefault("report", "")
    final.setdefault("summary", [])
    final.setdefault("updated_files", [])
    return final, raw1, raw2

# =============================================================================
# Anti-placeholder / sanitize
# =============================================================================
_PLACEHOLDER_PATTERNS = [
    r"conte[uú]do do arquivo",
    r"resultado[s]? dispon[ií]vel",
    r"placeholder",
]
def _looks_like_placeholder(text: str) -> bool:
    t = (text or "").lower()
    if len(t.strip()) < 8:
        return True
    for pat in _PLACEHOLDER_PATTERNS:
        if re.search(pat, t):
            return True
    return False

def _sanitize_llm_output(out: Dict[str, Any], *, allow_placeholders: bool) -> Dict[str, Any]:
    cleaned = {"report": "", "summary": [], "updated_files": []}
    cleaned["report"] = str(out.get("report", "") or "")
    cleaned["summary"] = [str(x) for x in (out.get("summary") or [])]
    seen = set()
    for f in (out.get("updated_files") or []):
        path = str(f.get("path", "")).strip()
        content = str(f.get("content", ""))
        if not path or not content.strip():
            continue
        if path in seen:
            continue
        if not allow_placeholders and _looks_like_placeholder(content):
            continue
        if path.lower().endswith(".py"):
            c = content
            if not any(tok in c for tok in ("def ", "class ", "import ", "if __name__")):
                # still allow if user opted to allow placeholders
                if not allow_placeholders:
                    continue
        seen.add(path)
        cleaned["updated_files"].append({"path": path, "content": content})
    return cleaned

# =============================================================================
# Misc
# =============================================================================
@app.middleware("http")
async def log_req_res(request: Request, call_next):
    try:
        body = (await request.body())[:500].decode(errors="ignore")
        log.info(f"{request.method} {request.url.path} body={body}")
    except Exception:
        pass
    resp = await call_next(request)
    log.info(f"RESP {request.url.path} status={resp.status_code}")
    return resp

@app.exception_handler(Exception)
async def all_exc_handler(request: Request, exc: Exception):
    log.exception("UNHANDLED")
    return JSONResponse(status_code=500, content={"detail": f"internal error: {type(exc).__name__}"})

@app.get("/health")
def health():
    return {"ok": True}

# =============================================================================
# Endpoint
# =============================================================================
@app.post("/compare", response_model=CompareOut)
def compare(body: CompareIn):
    gh = gh_client(body)

    # make bad/empty paths mean "whole repo"
    def _looks_bad(p: str) -> bool:
        return ("/" not in p) and not any(ch in p for ch in "*?[")
    include_paths = body.include_paths or ["/"]
    if include_paths and all(_looks_bad(p) for p in include_paths):
        include_paths = ["/"]

    try:
        code, nfiles, nbytes = extract_numbered_code(
            gh,
            body.repo,
            body.branch or "main",
            body.include_ext,
            include_paths,
            body.max_files,
            body.max_bytes,
        )
    except Exception as e:
        raise HTTPException(400, f"Falha ao ler repositório: {e}")

    if not code.strip():
        raise HTTPException(400, "Nenhum arquivo elegível encontrado (ext/paths).")

    if body.debug_no_llm:
        return {
            "report": f"[debug_no_llm] arquivos={nfiles} bytes={nbytes}",
            "summary": [f"Coletados {nfiles} arquivos (~{nbytes} bytes)"],
            "updated_files": [],
        }

    # Resolve LLM config
    api_url = (body.llm_api_url or os.getenv("LLM_API_URL") or "https://api.groq.com/openai/v1/chat/completions").strip()
    api_key = (body.llm_api_key or body.groq_api_key or os.getenv("LLM_API_KEY") or os.getenv("GROQ_API_KEY") or "").strip()
    model   = (body.model or os.getenv("LLM_MODEL") or os.getenv("GROQ_MODEL") or "llama-3.1-8b-instant").strip()

    if not api_key:
        raise HTTPException(
            400,
            "LLM desabilitado: passe 'debug_no_llm=true' OU forneça 'llm_api_key'/'LLM_API_KEY'."
        )

    try:
        out, raw1, raw2 = llm_refactor_review(api_url, api_key, body.requisitos, code, body.prompt_base, model)
    except requests.HTTPError as e:
        txt = (e.response.text or "")[:400]
        status = getattr(e.response, "status_code", 502)
        if status == 429 or "rate_limit" in txt or "rate_limit_exceeded" in txt:
            raise HTTPException(429, f"Erro ao chamar LLM (rate limit): {txt}")
        raise HTTPException(502, f"Erro ao chamar LLM: {txt}")
    except Exception as e:
        raise HTTPException(502, f"Erro ao chamar LLM: {e}")

    out_sane = _sanitize_llm_output(
        {"report": out.get("report", ""), "summary": out.get("summary", []), "updated_files": out.get("updated_files", [])},
        allow_placeholders=body.allow_placeholders,
    )
    report = out_sane["report"]
    summary = out_sane["summary"]
    files = out_sane["updated_files"]

    if not report.strip() and (summary or files):
        head = "; ".join(summary)[:240] if summary else f"{len(files)} arquivo(s) sugeridos"
        report = head

    resp = {"report": report, "summary": summary, "updated_files": files}
    if body.debug_echo_raw:
        # attach truncated raw for inspection
        raw_combined = (raw2 or raw1 or "")[:8000]
        resp["raw"] = raw_combined
    return resp

def _repo_and_ref(g: Github, repo_name: str, branch: Optional[str]) -> Tuple[Any, str]:
    repo = g.get_repo(repo_name)
    ref = branch or repo.default_branch or "main"
    try:
        repo.get_contents("", ref=ref)
        return repo, ref
    except GithubException:
        try:
            fallback = repo.default_branch or "main"
            if fallback != ref:
                repo.get_contents("", ref=fallback)
                return repo, fallback
        except Exception:
            pass
        raise
````

## server/app/__init__.py

```python

```

## server/pytest.ini

```text
[pytest]
pythonpath = .
markers =
    live_llm: tests that hit a live Groq model
```

## server/README.md

````markdown
# Server (FastAPI) — Compare API

## Setup
```bash
cd server
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env   # preencha se quiser
uvicorn app.main:app --reload
```
API: `http://127.0.0.1:8000/compare` (POST)

## Body (exemplo)
```json
{
  "repo": "org/repo",
  "branch": "main",
  "include_ext": [".py",".js",".java"],
  "include_paths": ["src/"],
  "requisitos": "texto",
  "github_pat": null,
  "groq_api_key": null
}
```

## Resposta
```json
{ "report": "...", "summary": ["..."], "updated_files": [{"path":"...","content":"..."}] }
```
````

## server/requirements.txt

```text
fastapi==0.112.0
uvicorn[standard]==0.30.6
python-dotenv==1.0.1
PyGithub==2.5.0
requests>=2.31.0
httpx>=0.27.2
```

## server/tests/conftest.py

```python
# server/tests/conftest.py
import os, sys, pathlib
ROOT = pathlib.Path(__file__).resolve().parents[1]  # .../server
sys.path.insert(0, str(ROOT))
```

## server/tests/test_e2e_uvicorn_debug.py

```python
import os, requests, itertools
from ._e2e_utils import UvicornProc

API = "http://127.0.0.1:8123"

def test_e2e_debug_no_llm():
    env = {
        # Make sure CORS is permissive for local manual tests as well:
        "ALLOWED_ORIGINS": "http://127.0.0.1:5501,*",
        # Ensure a valid non-deprecated default model if someone forgets debug flag later:
        "GROQ_MODEL": os.environ.get("GROQ_MODEL", "openai/gpt-oss-20b"),
    }
    with UvicornProc(port=8123, env=env):
        # health
        r = requests.get(f"{API}/health", timeout=10)
        assert r.ok and r.json().get("ok") is True

        # e2e compare with debug_no_llm (no Groq call)
        body = {
            "repo": "fromLELI/storycompare-with-LLM",
            "branch": "main",
            "include_ext": [".py", ".js", ".java"],
            "include_paths": ["/"],              # keep broad on purpose
            "requisitos": "Sem codigo duplicado!",
            "debug_no_llm": True,
            "max_files": 12,                     # keep token small if someone toggles flag
            "max_bytes": 200_000
        }
        r = requests.post(f"{API}/compare", json=body, timeout=60)
        assert r.ok, r.text
        j = r.json()
        assert "report" in j and "summary" in j and "updated_files" in j
        assert isinstance(j["summary"], list)
        # Debug path should not produce any updated_files:
        assert j["updated_files"] == []
```

## server/tests/test_e2e_uvicorn_live_llm.py

```python
# server/tests/test_e2e_uvicorn_live_llm.py
import os, requests, pytest
from ._e2e_utils import UvicornProc

API = "http://127.0.0.1:8124"

@pytest.mark.live_llm
@pytest.mark.skipif(not os.getenv("GROQ_API_KEY"), reason="GROQ_API_KEY not set")
def test_e2e_live_llm_roundtrip():
    env = {
        "ALLOWED_ORIGINS": "http://127.0.0.1:5501,*",
        "GROQ_MODEL": "llama-3.1-8b-instant",
        "GROQ_API_KEY": os.environ["GROQ_API_KEY"],
    }
    with UvicornProc(port=8124, env=env):
        r = requests.get(f"{API}/health", timeout=10)
        assert r.ok and r.json().get("ok") is True

        body = {
            "repo": "fromLELI/storycompare-with-LLM",
            "branch": "main",
            "include_ext": [".py"],
            "include_paths": ["/"],          # allow all so we don't miss files
            "requisitos": "Sem codigo duplicado!",
            "debug_no_llm": False,
            "max_files": 3,
            "max_bytes": 60_000,
            "model": "llama-3.1-8b-instant",
        }
        r = requests.post(f"{API}/compare", json=body, timeout=120)
        if r.status_code == 429:
            pytest.skip("rate-limited (TPM). Retry later.")
        assert r.ok, r.text
        j = r.json()
        assert isinstance(j.get("report",""), str)
        assert isinstance(j.get("summary", []), list)
        assert isinstance(j.get("updated_files", []), list)
        for f in j.get("updated_files", []):
            assert "path" in f and "content" in f
```

## server/tests/test_extract_crawl.py

```python
from app.main import extract_numbered_code, file_allowed

class _FakeContent:
    def __init__(self, path, typ, data=b""):
        self.path = path
        self.type = typ
        self._data = data
    @property
    def decoded_content(self):
        if self.type != "file":
            raise RuntimeError("no content")
        return self._data

class _FakeRepo:
    default_branch = "main"
    def __init__(self):
        # tree:
        #   src/a.py   "print(1)\n"
        #   src/b.js   "console.log(2)\n"
        #   static/x.css "..."
        self._root = [
            _FakeContent("src", "dir"),
            _FakeContent("static", "dir"),
        ]
        self._src = [
            _FakeContent("src/a.py", "file", b"print(1)\n"),
            _FakeContent("src/b.js", "file", b"console.log(2)\n"),
        ]
        self._static = [
            _FakeContent("static/x.css", "file", b"body{}"),
        ]
    def get_contents(self, path, ref="main"):
        if path == "":
            return list(self._root)
        if path == "src":
            return list(self._src)
        if path == "static":
            return list(self._static)
        raise FileNotFoundError(path)

class _FakeGH:
    def get_repo(self, name):
        assert name == "org/repo" or name == "fromLELI/storycompare-with-LLM"
        return _FakeRepo()

def test_extract_numbered_code_filters_and_limits():
    code, nfiles, nbytes = extract_numbered_code(
        _FakeGH(), "org/repo", "main",
        include_ext=[".py",".js"], include_paths=["src/"],
        max_files=10, max_bytes=1_000_000,
    )
    assert "### src/a.py" in code and "1: print(1)" in code
    assert "### src/b.js" in code and "1: console.log(2)" in code
    assert "static/x.css" not in code
    assert nfiles == 2 and nbytes > 0
```

## server/tests/test_filters.py

```python
# server/tests/test_filters.py
from app.main import file_allowed

def test_file_allowed_glob_and_slash():
    assert file_allowed("src/a.py", [".py"], ["/"])
    assert file_allowed("src/pkg/a.py", [".py"], ["src/**/*.py"])
    assert file_allowed("src/pkg/a.py", ["py"], ["src/"])
    assert not file_allowed("static/a.css", [".py"], ["src/"])
```

## server/tests/test_groq_env.py

```python
# tests/test_groq_env.py
import os
import pytest
import requests

API_URL = "https://api.groq.com/openai/v1/models"

@pytest.mark.skipif(not os.getenv("GROQ_API_KEY"), reason="sem GROQ key")
def test_groq_models_list():
    headers = {
        "Authorization": f"Bearer {os.getenv('GROQ_API_KEY')}",
    }
    try:
        resp = requests.get(API_URL, headers=headers, timeout=10)
        resp.raise_for_status()
        models = resp.json()
    except Exception as e:
        pytest.skip(f"rede/ambiente: {e}")
    assert "data" in models
```

## server/tests/test_paths_exts.py

```python
from app.main import _norm_exts, _norm_path, _path_matches_any, file_allowed

def test_norm_exts_accepts_dot_or_not():
    assert _norm_exts([".py","js","  JAVA "]) == [".py",".js",".java"]

def test_norm_path_normalizes_slashes():
    assert _norm_path(r"app\\main.py") == "app/main.py"
    assert _norm_path("app\\\\main.py") == "app/main.py"
    assert _norm_path("app///main.py") == "app/main.py"
    
def test_path_matches_any_prefix_and_glob():
    assert _path_matches_any("src/a.py", ["src/"])
    assert _path_matches_any("src/pkg/x.py", ["src/**/*.py"])
    assert _path_matches_any("anything/here", ["/"])  # wildcard
    assert not _path_matches_any("static/a.css", ["src/"])

def test_file_allowed_combo():
    assert file_allowed("src/a.py", [".py"], ["src/"])
    assert file_allowed("src/pkg/a.py", ["py"], ["src/**/*.py"])
    assert not file_allowed("assets/x.css", [".py"], ["src/"])
```

## server/tests/test_repo_ref_fallback.py

```python
import types
from github.GithubException import GithubException
from app.main import _repo_and_ref

class _RepoWithFallback:
    def __init__(self):
        self.default_branch = "main"
        self.calls = []
    def get_contents(self, path, ref="main"):
        self.calls.append((path, ref))
        if ref == "does-not-exist":
            raise GithubException(404, "not found", None)
        return []  # ok

class _GH:
    def get_repo(self, name):
        return _RepoWithFallback()

def test_repo_and_ref_fallback_to_default():
    repo, ref = _repo_and_ref(_GH(), "any/repo", "does-not-exist")
    assert ref == "main"
```

## server/tests/test_safe_json.py

````python
from app.main import safe_json

def test_safe_json_plain_ok():
    j = safe_json('{"report":"r","summary":["s"],"updated_files":[]}')
    assert j["report"] == "r" and j["summary"] == ["s"]

def test_safe_json_fenced_extraction():
    j = safe_json("```json\n{\"report\":\"ok\",\"summary\":[],\"updated_files\":[]}\n```")
    assert j["report"] == "ok"

def test_safe_json_broken_returns_stub():
    j = safe_json("nonsense")
    assert "report" in j and "updated_files" in j
````

## server/tests/_e2e_utils.py

```python
# server/tests/_e2e_utils.py
import os, time, socket, subprocess, sys
from contextlib import closing
from pathlib import Path

def wait_port(host: str, port: int, timeout: float = 10.0):
    t0 = time.time()
    while time.time() - t0 < timeout:
        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
            sock.settimeout(0.5)
            if sock.connect_ex((host, port)) == 0:
                return True
        time.sleep(0.1)
    return False

class UvicornProc:
    def __init__(self, host="127.0.0.1", port=8123, env=None):
        self.host = host
        self.port = port
        self.env = {**os.environ, **(env or {})}
        self.proc = None
        # repo_root = server/
        self.cwd = str(Path(__file__).resolve().parents[1])

    def __enter__(self):
        self.proc = subprocess.Popen(
            [sys.executable, "-m", "uvicorn", "app.main:app", "--host", self.host, "--port", str(self.port)],
            cwd=self.cwd,
            env=self.env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
        )
        if not wait_port(self.host, self.port, timeout=15):
            self.kill()
            raise RuntimeError("uvicorn did not start in time")
        return self

    def kill(self):
        if self.proc and self.proc.poll() is None:
            self.proc.terminate()
            try:
                self.proc.wait(timeout=5)
            except Exception:
                self.proc.kill()

    def __exit__(self, exc_type, exc, tb):
        self.kill()

    def stream_output(self):
        if not self.proc or not self.proc.stdout:
            return
        for line in self.proc.stdout:
            yield line.rstrip()
```

## server/tests/__init__.py

```python

```

## styles.css

```css
:root{--bg:#0d0d0f;--fg:#e6e6eb;--muted:#8a8a93;--accent:#ff2a6d;--ok:#24d18a;--card:#141418;--border:#1f1f25}
*{box-sizing:border-box}
html,body{height:100%}
body{margin:0;background:linear-gradient(180deg,#0b0b0d,#0e0e12);color:var(--fg);font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif}
header{padding:24px 20px 8px;display:flex;align-items:flex-end;gap:12px}
h1{margin:0;font-size:28px;letter-spacing:1px;text-transform:lowercase}
.sub{color:var(--muted);font-size:14px}
main{padding:12px 20px 40px;max-width:1200px;margin:0 auto}
.panel{background:var(--card);border:1px solid var(--border);border-radius:14px;padding:16px;margin-bottom:16px}
.row{display:flex;flex-direction:column;gap:8px;margin-bottom:12px}
.grid4{display:grid;grid-template-columns:repeat(4,1fr);gap:12px}
label{font-size:13px;color:var(--muted)}
select,textarea,input{width:100%;background:#0f0f13;color:var(--fg);border:1px solid var(--border);border-radius:10px;padding:12px;font-size:14px;outline:none;transition:border-color .15s, box-shadow .15s}

textarea{
  min-height:260px;
  resize:none;
  overflow:hidden;
  scrollbar-width:none;
  font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,"Cascadia Code","Fira Code",Consolas,"Liberation Mono",monospace;
  line-height:1.35;
  caret-color:var(--accent);
}
textarea::-webkit-scrollbar{width:0;height:0}

select:focus,textarea:focus,input:focus{border-color:#2b2b34;box-shadow:0 0 0 3px rgba(255,42,109,.12) inset}
.actions{display:flex;gap:8px;align-items:center}
.actions.below{margin-top:12px;justify-content:flex-start}
button{background:var(--accent);color:#fff;border:none;border-radius:10px;padding:12px 16px;font-weight:700;text-transform:lowercase;letter-spacing:.3px;cursor:pointer;transition:filter .2s}
button:hover{filter:brightness(1.1)}
button.toggle{background:#333;font-size:12px;padding:8px 12px;border-radius:8px;text-transform:none}
button.toggle.active{background:var(--accent)}
.muted{color:var(--muted);font-size:12px}

.output .columns{display:grid;grid-template-columns:1fr 1fr;gap:16px}
.output h3{margin:8px 0;font-size:14px;color:var(--muted)}
pre{background:#0f0f13;border:1px solid var(--border);padding:12px;border-radius:10px;overflow:auto;max-height:360px;white-space:pre-wrap}
.meta{margin-top:12px}

#overlay{position:fixed;inset:0;backdrop-filter:blur(4px);background:rgba(0,0,0,.35);display:none;align-items:center;justify-content:center;flex-direction:column;gap:10px;z-index:10}
.loader{width:28px;height:28px;border-radius:50%;border:3px solid #333;border-top-color:var(--accent);animation:spin 1s linear infinite}
.msg{color:var(--muted);font-size:14px}
.save{margin-top:8px}
@keyframes spin{to{transform:rotate(360deg)}}

@media (max-width:1100px){.grid4{grid-template-columns:1fr 1fr}}
@media (max-width:900px){.output .columns{grid-template-columns:1fr}}

.code-wrap{position:relative}
.code-wrap textarea{width:100%;height:auto}
.code-wrap.collapsed textarea{
  max-height:var(--ta-max,320px);
  mask-image:linear-gradient(to bottom, rgba(0,0,0,1) 65%, rgba(0,0,0,0));
}
.code-wrap .ghost{
  position:absolute;right:12px;bottom:12px;background:#1b1b22;border:1px solid var(--border);color:var(--fg);
  padding:6px 10px;font-size:12px;border-radius:8px;
}
.code-wrap .ghost:hover{opacity:.9}
```

## Statistics

- Total Files: 28
- Total Characters: 65149
- Total Tokens: 0
`````

## reqs.txt

```text
Refatore para:
- evitar código duplicado;
- extrair funções utilitárias em comparador.py;
- adicionar checagem de extensões suportadas;
- retornar códigos de saída adequados;
- manter compatibilidade com tests/.
```

## server/app/main.py

````python
import os, base64, logging, fnmatch, time, re
from typing import List, Optional, Dict, Any, Tuple
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from github import Github, GithubIntegration
from github.GithubException import GithubException
from dotenv import load_dotenv
import requests

load_dotenv()

ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "*")
allow_origins = ["*"] if ALLOWED_ORIGINS.strip() == "*" else [
    o.strip() for o in ALLOWED_ORIGINS.split(",") if o.strip()
]
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=allow_origins,
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

log = logging.getLogger("uvicorn.error")

# =============================================================================
# Models
# =============================================================================
class CompareIn(BaseModel):
    repo: str
    branch: Optional[str] = "main"
    include_ext: List[str] = Field(default_factory=lambda: [".py", ".js", ".java"])
    include_paths: List[str] = Field(default_factory=list)
    requisitos: str
    prompt_base: Optional[str] = None
    max_files: int = 200
    max_bytes: int = 800_000
    debug_no_llm: bool = False

    # Generic LLM config
    llm_api_url: Optional[str] = None
    llm_api_key: Optional[str] = None
    model: Optional[str] = None

    # Back-compat (prefer generic fields above)
    groq_api_key: Optional[str] = None

    # Optional GitHub App BYOK
    github_pat: Optional[str] = None
    github_app_id: Optional[str] = None
    github_installation_id: Optional[str] = None
    github_private_key_pem_b64: Optional[str] = None

    # NEW: debugging / filtering toggles
    debug_echo_raw: bool = False
    allow_placeholders: bool = False

class FileOut(BaseModel):
    path: str
    content: str

class CompareOut(BaseModel):
    report: str
    summary: List[str]
    updated_files: List[FileOut]
    raw: Optional[str] = None

# =============================================================================
# GitHub helpers
# =============================================================================
def gh_via_pat(pat: str) -> Github:
    return Github(pat, timeout=30)

def gh_via_app(app_id: str, installation_id: str, private_key_pem: str) -> Github:
    integ = Github(app_id, private_key_pem)
    token = integ.get_access_token(int(installation_id)).token
    return Github(token, timeout=30)

def gh_client(body: CompareIn) -> Github:
    if body.github_pat:
        return gh_via_pat(body.github_pat)
    if body.github_app_id and body.github_installation_id and body.github_private_key_pem_b64:
        pem = base64.b64decode(body.github_private_key_pem_b64).decode("utf-8")
        return gh_via_app(body.github_app_id, body.github_installation_id, pem)
    app_id = os.getenv("GITHUB_APP_ID")
    inst_id = os.getenv("GITHUB_INSTALLATION_ID")
    key_path = os.getenv("GITHUB_PRIVATE_KEY_PATH")
    if app_id and inst_id and key_path and os.path.exists(key_path):
        with open(key_path, "r") as f:
            pem = f.read()
        return gh_via_app(app_id, inst_id, pem)
    return Github(timeout=30)

# =============================================================================
# Filters
# =============================================================================
def _norm_exts(exts: List[str]) -> List[str]:
    out = []
    for e in exts or []:
        e = e.strip().lower()
        if not e:
            continue
        if e == "*":
            return []  # wildcard = no filter
        if not e.startswith("."):
            e = "." + e
        out.append(e)
    return out

def _norm_path(p: str) -> str:
    out = (p or "").replace("\\", "/")
    while "//" in out:
        out = out.replace("//", "/")
    return out

def _path_matches_any(path: str, patterns: List[str]) -> bool:
    if not patterns:
        return True
    if any(p.strip() == "/" for p in patterns):
        return True
    p_norm = _norm_path(path).lstrip("/")
    for raw in patterns:
        pat = _norm_path(raw).lstrip("/")
        if any(ch in pat for ch in ["*", "?", "["]):
            if fnmatch.fnmatch(p_norm, pat):
                return True
        if p_norm.startswith(pat):
            return True
    return False

def file_allowed(path: str, exts: List[str], include_paths: List[str]) -> bool:
    p = _norm_path(path)
    exts_norm = _norm_exts(exts)
    if exts_norm and not any(p.lower().endswith(e) for e in exts_norm):
        return False
    if not _path_matches_any(p, include_paths):
        return False
    return True

def extract_numbered_code(
    g: Github,
    repo_name: str,
    branch: str,
    include_ext: List[str],
    include_paths: List[str],
    max_files: int,
    max_bytes: int,
) -> Tuple[str, int, int]:
    repo, ref = _repo_and_ref(g, repo_name, branch)
    contents = repo.get_contents("", ref=ref)
    chunks: List[str] = []
    nfiles = 0
    nbytes = 0

    while contents:
        it = contents.pop(0)
        if it.type == "dir":
            dir_path = _norm_path(it.path).rstrip("/") + "/"
            if include_paths and not _path_matches_any(dir_path, include_paths):
                keep = any(_norm_path(p).lstrip("/").startswith(dir_path) for p in include_paths)
                if not keep:
                    continue
            contents.extend(repo.get_contents(it.path, ref=ref))
            continue

        if not file_allowed(it.path, include_ext, include_paths):
            continue

        try:
            blob = it.decoded_content
        except Exception:
            continue

        nfiles += 1
        nbytes += len(blob)
        if nfiles > max_files or nbytes > max_bytes:
            break

        snippet = blob.decode(errors="ignore")
        lines = snippet.splitlines()[:800]
        snippet = "\n".join(lines)
        numbered = "\n".join(f"{i+1}: {line}" for i, line in enumerate(snippet.splitlines()))
        chunks.append(f"### {it.path}\n{numbered}")

    return ("\n\n".join(chunks), nfiles, nbytes)

# =============================================================================
# LLM glue (OpenAI-compatible + Gemini)
# =============================================================================
REF_PROMPT_HDR = (
    "Você é um engenheiro sênior. RETORNE SOMENTE JSON válido em UTF-8, sem markdown, sem comentários.\n"
    "Formato obrigatório: {\"report\":\"...\",\"summary\":[\"...\"],\"updated_files\":[{\"path\":\"...\",\"content\":\"...\"}]}\n"
)

def safe_json(s: str) -> Dict[str, Any]:
    import json
    s = (s or "").strip()
    try:
        j = json.loads(s)
        if isinstance(j, dict):
            return j
    except Exception:
        pass
    m = re.search(r"```(?:json)?\s*([\s\S]*?)```", s or "", re.I)
    if m:
        try:
            j = json.loads(m.group(1))
            if isinstance(j, dict):
                return j
        except Exception:
            pass
    return {"report": "", "summary": [], "updated_files": [], "_raw": s}

def _is_gemini_url(api_url: str) -> bool:
    return "generativelanguage.googleapis.com" in (api_url or "")

def _openai_chat(api_url: str, api_key: str, model: str, messages: list, *, temperature=0.2, top_p=0.9) -> str:
    url = api_url or "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}"}
    payload = {"model": model, "messages": messages, "temperature": temperature, "top_p": top_p}
    for attempt in range(3):
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        status = getattr(r, "status_code", 200)
        if status == 429:
            delay = float(r.headers.get("Retry-After", 1.5 * (attempt + 1)))
            time.sleep(delay)
            continue
        if status >= 400:
            r.raise_for_status()
        j = r.json()
        return j["choices"][0]["message"]["content"]
    r.raise_for_status()
    raise RuntimeError("unexpected")

def _gemini_generate(api_base: str, api_key: str, model: str, user_text: str, *, temperature=0.2, top_p=0.9) -> str:
    base = api_base.rstrip("/")
    endpoint = f"{base}/models/{model}:generateContent?key={api_key}"
    payload = {
        "contents": [ {"role": "user", "parts": [{"text": user_text}]} ],
        "generationConfig": {"temperature": temperature, "topP": top_p}
    }
    for attempt in range(3):
        r = requests.post(endpoint, json=payload, timeout=60)
        status = getattr(r, "status_code", 200)
        if status == 429:
            delay = float(r.headers.get("Retry-After", 1.5 * (attempt + 1)))
            time.sleep(delay)
            continue
        if status >= 400:
            r.raise_for_status()
        j = r.json()
        cands = (j or {}).get("candidates") or []
        if not cands:
            return ""
        parts = (cands[0].get("content") or {}).get("parts") or []
        out = []
        for p in parts:
            t = p.get("text", "")
            if t:
                out.append(t)
        return "\n".join(out).strip()
    r.raise_for_status()
    raise RuntimeError("unexpected")

def _call_llm_text(api_url: str, api_key: str, model: str, messages: list) -> str:
    if _is_gemini_url(api_url):
        # flatten to one "user" turn for Gemini
        buf = []
        for m in messages:
            role = m.get("role") or "user"
            content = m.get("content") or ""
            if role == "system":
                buf.append(f"[SYSTEM]\n{content}")
            else:
                buf.append(content)
        user_text = "\n\n".join(buf)
        return _gemini_generate(api_url, api_key, model, user_text)
    else:
        return _openai_chat(api_url, api_key, model, messages)

def call_llm_json(api_url: str, api_key: str, model: str, messages: list) -> Tuple[Dict[str, Any], str]:
    text = _call_llm_text(api_url, api_key, model, messages)
    return safe_json(text), text

def llm_refactor_review(api_url: str, api_key: str, requisitos: str, codigo: str, prompt_base: Optional[str], model: str) -> Tuple[Dict[str, Any], str, str]:
    base = prompt_base or ""
    m1 = [
        {"role": "system", "content": REF_PROMPT_HDR + base},
        {"role": "user", "content": f"=== REQUISITOS ===\n{requisitos}\n\n=== CODIGO NUMERADO ===\n{codigo}"},
    ]
    j1, raw1 = call_llm_json(api_url, api_key, model, m1)

    repair_instr = (
        "Valide que o JSON possui as chaves 'report', 'summary'(lista), 'updated_files'(lista de objetos com 'path' e 'content').\n"
        "Se algo faltar, corrija. Retorne SOMENTE JSON válido."
    )
    m2 = [
        {"role": "system", "content": REF_PROMPT_HDR + repair_instr},
        {"role": "user", "content": str(j1)},
    ]
    j2, raw2 = call_llm_json(api_url, api_key, model, m2)

    def looks_ok(j):
        return isinstance(j.get("updated_files"), list) and isinstance(j.get("summary"), list) and isinstance(j.get("report"), str)

    final = j2 if looks_ok(j2) else j1
    final.setdefault("report", "")
    final.setdefault("summary", [])
    final.setdefault("updated_files", [])
    return final, raw1, raw2

# =============================================================================
# Anti-placeholder / sanitize
# =============================================================================
_PLACEHOLDER_PATTERNS = [
    r"conte[uú]do do arquivo",
    r"resultado[s]? dispon[ií]vel",
    r"placeholder",
]
def _looks_like_placeholder(text: str) -> bool:
    t = (text or "").lower()
    if len(t.strip()) < 8:
        return True
    for pat in _PLACEHOLDER_PATTERNS:
        if re.search(pat, t):
            return True
    return False

def _sanitize_llm_output(out: Dict[str, Any], *, allow_placeholders: bool) -> Dict[str, Any]:
    cleaned = {"report": "", "summary": [], "updated_files": []}
    cleaned["report"] = str(out.get("report", "") or "")
    cleaned["summary"] = [str(x) for x in (out.get("summary") or [])]
    seen = set()
    for f in (out.get("updated_files") or []):
        path = str(f.get("path", "")).strip()
        content = str(f.get("content", ""))
        if not path or not content.strip():
            continue
        if path in seen:
            continue
        if not allow_placeholders and _looks_like_placeholder(content):
            continue
        if path.lower().endswith(".py"):
            c = content
            if not any(tok in c for tok in ("def ", "class ", "import ", "if __name__")):
                # still allow if user opted to allow placeholders
                if not allow_placeholders:
                    continue
        seen.add(path)
        cleaned["updated_files"].append({"path": path, "content": content})
    return cleaned

# =============================================================================
# Misc
# =============================================================================
@app.middleware("http")
async def log_req_res(request: Request, call_next):
    try:
        body = (await request.body())[:500].decode(errors="ignore")
        log.info(f"{request.method} {request.url.path} body={body}")
    except Exception:
        pass
    resp = await call_next(request)
    log.info(f"RESP {request.url.path} status={resp.status_code}")
    return resp

@app.exception_handler(Exception)
async def all_exc_handler(request: Request, exc: Exception):
    log.exception("UNHANDLED")
    return JSONResponse(status_code=500, content={"detail": f"internal error: {type(exc).__name__}"})

@app.get("/health")
def health():
    return {"ok": True}

# =============================================================================
# Endpoint
# =============================================================================
@app.post("/compare", response_model=CompareOut)
def compare(body: CompareIn):
    gh = gh_client(body)

    # make bad/empty paths mean "whole repo"
    def _looks_bad(p: str) -> bool:
        return ("/" not in p) and not any(ch in p for ch in "*?[")
    include_paths = body.include_paths or ["/"]
    if include_paths and all(_looks_bad(p) for p in include_paths):
        include_paths = ["/"]

    try:
        code, nfiles, nbytes = extract_numbered_code(
            gh,
            body.repo,
            body.branch or "main",
            body.include_ext,
            include_paths,
            body.max_files,
            body.max_bytes,
        )
    except Exception as e:
        raise HTTPException(400, f"Falha ao ler repositório: {e}")

    if not code.strip():
        raise HTTPException(400, "Nenhum arquivo elegível encontrado (ext/paths).")

    if body.debug_no_llm:
        return {
            "report": f"[debug_no_llm] arquivos={nfiles} bytes={nbytes}",
            "summary": [f"Coletados {nfiles} arquivos (~{nbytes} bytes)"],
            "updated_files": [],
        }

    # Resolve LLM config
    api_url = (body.llm_api_url or os.getenv("LLM_API_URL") or "https://api.groq.com/openai/v1/chat/completions").strip()
    api_key = (body.llm_api_key or body.groq_api_key or os.getenv("LLM_API_KEY") or os.getenv("GROQ_API_KEY") or "").strip()
    model   = (body.model or os.getenv("LLM_MODEL") or os.getenv("GROQ_MODEL") or "llama-3.1-8b-instant").strip()

    if not api_key:
        raise HTTPException(
            400,
            "LLM desabilitado: passe 'debug_no_llm=true' OU forneça 'llm_api_key'/'LLM_API_KEY'."
        )

    try:
        out, raw1, raw2 = llm_refactor_review(api_url, api_key, body.requisitos, code, body.prompt_base, model)
    except requests.HTTPError as e:
        txt = (e.response.text or "")[:400]
        status = getattr(e.response, "status_code", 502)
        if status == 429 or "rate_limit" in txt or "rate_limit_exceeded" in txt:
            raise HTTPException(429, f"Erro ao chamar LLM (rate limit): {txt}")
        raise HTTPException(502, f"Erro ao chamar LLM: {txt}")
    except Exception as e:
        raise HTTPException(502, f"Erro ao chamar LLM: {e}")

    out_sane = _sanitize_llm_output(
        {"report": out.get("report", ""), "summary": out.get("summary", []), "updated_files": out.get("updated_files", [])},
        allow_placeholders=body.allow_placeholders,
    )
    report = out_sane["report"]
    summary = out_sane["summary"]
    files = out_sane["updated_files"]

    if not report.strip() and (summary or files):
        head = "; ".join(summary)[:240] if summary else f"{len(files)} arquivo(s) sugeridos"
        report = head

    resp = {"report": report, "summary": summary, "updated_files": files}
    if body.debug_echo_raw:
        # attach truncated raw for inspection
        raw_combined = (raw2 or raw1 or "")[:8000]
        resp["raw"] = raw_combined
    return resp

def _repo_and_ref(g: Github, repo_name: str, branch: Optional[str]) -> Tuple[Any, str]:
    repo = g.get_repo(repo_name)
    ref = branch or repo.default_branch or "main"
    try:
        repo.get_contents("", ref=ref)
        return repo, ref
    except GithubException:
        try:
            fallback = repo.default_branch or "main"
            if fallback != ref:
                repo.get_contents("", ref=fallback)
                return repo, fallback
        except Exception:
            pass
        raise
````

## server/app/__init__.py

```python

```

## server/pytest.ini

```text
[pytest]
pythonpath = .
markers =
    live_llm: tests that hit a live Groq model
```

## server/requirements.txt

```text
fastapi==0.112.0
uvicorn[standard]==0.30.6
python-dotenv==1.0.1
PyGithub==2.5.0
requests>=2.31.0
httpx>=0.27.2
```

## server/tests/conftest.py

```python
# server/tests/conftest.py
import os, sys, pathlib
ROOT = pathlib.Path(__file__).resolve().parents[1]  # .../server
sys.path.insert(0, str(ROOT))
```

## server/tests/test_e2e_uvicorn_debug.py

```python
import os, requests, itertools
from ._e2e_utils import UvicornProc

API = "http://127.0.0.1:8123"

def test_e2e_debug_no_llm():
    env = {
        # Make sure CORS is permissive for local manual tests as well:
        "ALLOWED_ORIGINS": "http://127.0.0.1:5501,*",
        # Ensure a valid non-deprecated default model if someone forgets debug flag later:
        "GROQ_MODEL": os.environ.get("GROQ_MODEL", "openai/gpt-oss-20b"),
    }
    with UvicornProc(port=8123, env=env):
        # health
        r = requests.get(f"{API}/health", timeout=10)
        assert r.ok and r.json().get("ok") is True

        # e2e compare with debug_no_llm (no Groq call)
        body = {
            "repo": "fromLELI/storycompare-with-LLM",
            "branch": "main",
            "include_ext": [".py", ".js", ".java"],
            "include_paths": ["/"],              # keep broad on purpose
            "requisitos": "Sem codigo duplicado!",
            "debug_no_llm": True,
            "max_files": 12,                     # keep token small if someone toggles flag
            "max_bytes": 200_000
        }
        r = requests.post(f"{API}/compare", json=body, timeout=60)
        assert r.ok, r.text
        j = r.json()
        assert "report" in j and "summary" in j and "updated_files" in j
        assert isinstance(j["summary"], list)
        # Debug path should not produce any updated_files:
        assert j["updated_files"] == []
```

## server/tests/test_e2e_uvicorn_live_llm.py

```python
# server/tests/test_e2e_uvicorn_live_llm.py
import os, requests, pytest
from ._e2e_utils import UvicornProc

API = "http://127.0.0.1:8124"

@pytest.mark.live_llm
@pytest.mark.skipif(not os.getenv("GROQ_API_KEY"), reason="GROQ_API_KEY not set")
def test_e2e_live_llm_roundtrip():
    env = {
        "ALLOWED_ORIGINS": "http://127.0.0.1:5501,*",
        "GROQ_MODEL": "llama-3.1-8b-instant",
        "GROQ_API_KEY": os.environ["GROQ_API_KEY"],
    }
    with UvicornProc(port=8124, env=env):
        r = requests.get(f"{API}/health", timeout=10)
        assert r.ok and r.json().get("ok") is True

        body = {
            "repo": "fromLELI/storycompare-with-LLM",
            "branch": "main",
            "include_ext": [".py"],
            "include_paths": ["/"],          # allow all so we don't miss files
            "requisitos": "Sem codigo duplicado!",
            "debug_no_llm": False,
            "max_files": 3,
            "max_bytes": 60_000,
            "model": "llama-3.1-8b-instant",
        }
        r = requests.post(f"{API}/compare", json=body, timeout=120)
        if r.status_code == 429:
            pytest.skip("rate-limited (TPM). Retry later.")
        assert r.ok, r.text
        j = r.json()
        assert isinstance(j.get("report",""), str)
        assert isinstance(j.get("summary", []), list)
        assert isinstance(j.get("updated_files", []), list)
        for f in j.get("updated_files", []):
            assert "path" in f and "content" in f
```

## server/tests/test_extract_crawl.py

```python
from app.main import extract_numbered_code, file_allowed

class _FakeContent:
    def __init__(self, path, typ, data=b""):
        self.path = path
        self.type = typ
        self._data = data
    @property
    def decoded_content(self):
        if self.type != "file":
            raise RuntimeError("no content")
        return self._data

class _FakeRepo:
    default_branch = "main"
    def __init__(self):
        # tree:
        #   src/a.py   "print(1)\n"
        #   src/b.js   "console.log(2)\n"
        #   static/x.css "..."
        self._root = [
            _FakeContent("src", "dir"),
            _FakeContent("static", "dir"),
        ]
        self._src = [
            _FakeContent("src/a.py", "file", b"print(1)\n"),
            _FakeContent("src/b.js", "file", b"console.log(2)\n"),
        ]
        self._static = [
            _FakeContent("static/x.css", "file", b"body{}"),
        ]
    def get_contents(self, path, ref="main"):
        if path == "":
            return list(self._root)
        if path == "src":
            return list(self._src)
        if path == "static":
            return list(self._static)
        raise FileNotFoundError(path)

class _FakeGH:
    def get_repo(self, name):
        assert name == "org/repo" or name == "fromLELI/storycompare-with-LLM"
        return _FakeRepo()

def test_extract_numbered_code_filters_and_limits():
    code, nfiles, nbytes = extract_numbered_code(
        _FakeGH(), "org/repo", "main",
        include_ext=[".py",".js"], include_paths=["src/"],
        max_files=10, max_bytes=1_000_000,
    )
    assert "### src/a.py" in code and "1: print(1)" in code
    assert "### src/b.js" in code and "1: console.log(2)" in code
    assert "static/x.css" not in code
    assert nfiles == 2 and nbytes > 0
```

## server/tests/test_filters.py

```python
# server/tests/test_filters.py
from app.main import file_allowed

def test_file_allowed_glob_and_slash():
    assert file_allowed("src/a.py", [".py"], ["/"])
    assert file_allowed("src/pkg/a.py", [".py"], ["src/**/*.py"])
    assert file_allowed("src/pkg/a.py", ["py"], ["src/"])
    assert not file_allowed("static/a.css", [".py"], ["src/"])
```

## server/tests/test_groq_env.py

```python
# tests/test_groq_env.py
import os
import pytest
import requests

API_URL = "https://api.groq.com/openai/v1/models"

@pytest.mark.skipif(not os.getenv("GROQ_API_KEY"), reason="sem GROQ key")
def test_groq_models_list():
    headers = {
        "Authorization": f"Bearer {os.getenv('GROQ_API_KEY')}",
    }
    try:
        resp = requests.get(API_URL, headers=headers, timeout=10)
        resp.raise_for_status()
        models = resp.json()
    except Exception as e:
        pytest.skip(f"rede/ambiente: {e}")
    assert "data" in models
```

## server/tests/test_paths_exts.py

```python
from app.main import _norm_exts, _norm_path, _path_matches_any, file_allowed

def test_norm_exts_accepts_dot_or_not():
    assert _norm_exts([".py","js","  JAVA "]) == [".py",".js",".java"]

def test_norm_path_normalizes_slashes():
    assert _norm_path(r"app\\main.py") == "app/main.py"
    assert _norm_path("app\\\\main.py") == "app/main.py"
    assert _norm_path("app///main.py") == "app/main.py"
    
def test_path_matches_any_prefix_and_glob():
    assert _path_matches_any("src/a.py", ["src/"])
    assert _path_matches_any("src/pkg/x.py", ["src/**/*.py"])
    assert _path_matches_any("anything/here", ["/"])  # wildcard
    assert not _path_matches_any("static/a.css", ["src/"])

def test_file_allowed_combo():
    assert file_allowed("src/a.py", [".py"], ["src/"])
    assert file_allowed("src/pkg/a.py", ["py"], ["src/**/*.py"])
    assert not file_allowed("assets/x.css", [".py"], ["src/"])
```

## server/tests/test_repo_ref_fallback.py

```python
import types
from github.GithubException import GithubException
from app.main import _repo_and_ref

class _RepoWithFallback:
    def __init__(self):
        self.default_branch = "main"
        self.calls = []
    def get_contents(self, path, ref="main"):
        self.calls.append((path, ref))
        if ref == "does-not-exist":
            raise GithubException(404, "not found", None)
        return []  # ok

class _GH:
    def get_repo(self, name):
        return _RepoWithFallback()

def test_repo_and_ref_fallback_to_default():
    repo, ref = _repo_and_ref(_GH(), "any/repo", "does-not-exist")
    assert ref == "main"
```

## server/tests/test_safe_json.py

````python
from app.main import safe_json

def test_safe_json_plain_ok():
    j = safe_json('{"report":"r","summary":["s"],"updated_files":[]}')
    assert j["report"] == "r" and j["summary"] == ["s"]

def test_safe_json_fenced_extraction():
    j = safe_json("```json\n{\"report\":\"ok\",\"summary\":[],\"updated_files\":[]}\n```")
    assert j["report"] == "ok"

def test_safe_json_broken_returns_stub():
    j = safe_json("nonsense")
    assert "report" in j and "updated_files" in j
````

## server/tests/_e2e_utils.py

```python
# server/tests/_e2e_utils.py
import os, time, socket, subprocess, sys
from contextlib import closing
from pathlib import Path

def wait_port(host: str, port: int, timeout: float = 10.0):
    t0 = time.time()
    while time.time() - t0 < timeout:
        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:
            sock.settimeout(0.5)
            if sock.connect_ex((host, port)) == 0:
                return True
        time.sleep(0.1)
    return False

class UvicornProc:
    def __init__(self, host="127.0.0.1", port=8123, env=None):
        self.host = host
        self.port = port
        self.env = {**os.environ, **(env or {})}
        self.proc = None
        # repo_root = server/
        self.cwd = str(Path(__file__).resolve().parents[1])

    def __enter__(self):
        self.proc = subprocess.Popen(
            [sys.executable, "-m", "uvicorn", "app.main:app", "--host", self.host, "--port", str(self.port)],
            cwd=self.cwd,
            env=self.env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
        )
        if not wait_port(self.host, self.port, timeout=15):
            self.kill()
            raise RuntimeError("uvicorn did not start in time")
        return self

    def kill(self):
        if self.proc and self.proc.poll() is None:
            self.proc.terminate()
            try:
                self.proc.wait(timeout=5)
            except Exception:
                self.proc.kill()

    def __exit__(self, exc_type, exc, tb):
        self.kill()

    def stream_output(self):
        if not self.proc or not self.proc.stdout:
            return
        for line in self.proc.stdout:
            yield line.rstrip()
```

## server/tests/__init__.py

```python

```

## styles.css

```css
:root{--bg:#0d0d0f;--fg:#e6e6eb;--muted:#8a8a93;--accent:#ff2a6d;--ok:#24d18a;--card:#141418;--border:#1f1f25}
*{box-sizing:border-box}
html,body{height:100%}
body{margin:0;background:linear-gradient(180deg,#0b0b0d,#0e0e12);color:var(--fg);font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif}
header{padding:24px 20px 8px;display:flex;align-items:flex-end;gap:12px}
h1{margin:0;font-size:28px;letter-spacing:1px;text-transform:lowercase}
.sub{color:var(--muted);font-size:14px}
main{padding:12px 20px 40px;max-width:1200px;margin:0 auto}
.panel{background:var(--card);border:1px solid var(--border);border-radius:14px;padding:16px;margin-bottom:16px}
.row{display:flex;flex-direction:column;gap:8px;margin-bottom:12px}
.grid4{display:grid;grid-template-columns:repeat(4,1fr);gap:12px}
label{font-size:13px;color:var(--muted)}
select,textarea,input{width:100%;background:#0f0f13;color:var(--fg);border:1px solid var(--border);border-radius:10px;padding:12px;font-size:14px;outline:none;transition:border-color .15s, box-shadow .15s}

textarea{
  min-height:260px;
  resize:none;
  overflow:hidden;
  scrollbar-width:none;
  font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,"Cascadia Code","Fira Code",Consolas,"Liberation Mono",monospace;
  line-height:1.35;
  caret-color:var(--accent);
}
textarea::-webkit-scrollbar{width:0;height:0}

select:focus,textarea:focus,input:focus{border-color:#2b2b34;box-shadow:0 0 0 3px rgba(255,42,109,.12) inset}
.actions{display:flex;gap:8px;align-items:center}
.actions.below{margin-top:12px;justify-content:flex-start}
button{background:var(--accent);color:#fff;border:none;border-radius:10px;padding:12px 16px;font-weight:700;text-transform:lowercase;letter-spacing:.3px;cursor:pointer;transition:filter .2s}
button:hover{filter:brightness(1.1)}
button.toggle{background:#333;font-size:12px;padding:8px 12px;border-radius:8px;text-transform:none}
button.toggle.active{background:var(--accent)}
.muted{color:var(--muted);font-size:12px}

.output .columns{display:grid;grid-template-columns:1fr 1fr;gap:16px}
.output h3{margin:8px 0;font-size:14px;color:var(--muted)}
pre{background:#0f0f13;border:1px solid var(--border);padding:12px;border-radius:10px;overflow:auto;max-height:360px;white-space:pre-wrap}
.meta{margin-top:12px}

#overlay{position:fixed;inset:0;backdrop-filter:blur(4px);background:rgba(0,0,0,.35);display:none;align-items:center;justify-content:center;flex-direction:column;gap:10px;z-index:10}
.loader{width:28px;height:28px;border-radius:50%;border:3px solid #333;border-top-color:var(--accent);animation:spin 1s linear infinite}
.msg{color:var(--muted);font-size:14px}
.save{margin-top:8px}
@keyframes spin{to{transform:rotate(360deg)}}

@media (max-width:1100px){.grid4{grid-template-columns:1fr 1fr}}
@media (max-width:900px){.output .columns{grid-template-columns:1fr}}

.code-wrap{position:relative}
.code-wrap textarea{width:100%;height:auto}
.code-wrap.collapsed textarea{
  max-height:var(--ta-max,320px);
  mask-image:linear-gradient(to bottom, rgba(0,0,0,1) 65%, rgba(0,0,0,0));
}
.code-wrap .ghost{
  position:absolute;right:12px;bottom:12px;background:#1b1b22;border:1px solid var(--border);color:var(--fg);
  padding:6px 10px;font-size:12px;border-radius:8px;
}
.code-wrap .ghost:hover{opacity:.9}
```

## Statistics

- Total Files: 22
- Total Characters: 113812
- Total Tokens: 0
